# Transformerå­¦ä¹ å¤§çº²

**User:** Anonymous (bonedarwin561@outlook.com)  
**Created:** 8/19/2025 17:40  
**Updated:** 8/20/2025 10:11  
**Exported:** 8/20/2025 10:13  
**Link:** [https://chatgpt.com/c/68a4469a-28cc-8329-8076-5f5698870277?model=gpt-5-thinking](https://chatgpt.com/c/68a4469a-28cc-8329-8076-5f5698870277?model=gpt-5-thinking)  

## Prompt:
01-Transformer.pdf

PDF

Task: æ·±å…¥å­¦ä¹ ç ”ç©¶Transformerè®ºæ–‡é‡Œé¢çš„æŠ€æœ¯ç»†èŠ‚å’Œåº•å±‚æœºåˆ¶

Methid: è€å¿ƒå¼•å¯¼å¼&é€‰æ‹©é¢˜æé—®å¼&çŸ¥è¯†å¡ç‰‡/QAé—ªå¡æ€»ç»“å¼&interesting-examples/jokes-driven&ä¸€æ­¥ä¸€æ­¥æ‹†è§£åˆ†æ

Bonus&CandyğŸ¬:colorful emoji & å¹½é»˜æœ‰è¶£ & æœ‰æ€æƒ³æ·±åº¦ & å›¾è§£/é—ªå¡ & funny games

Notice: æˆ‘ä»¬å¯ä»¥quoteåŸæ–‡ä¸­çš„æ ¸å¿ƒå¥å­&æ¯éš”å‡ æ®µè¿›è¡Œæ€»ç»“å¤ä¹ 

é¦–å…ˆç»™å‡ºå­¦ä¹ å¤§çº²

## Response:
æˆ‘ä»¬å°†ç”¨ä½ å–œæ¬¢çš„å¼•å¯¼å¼ + é—ªå¡å¼ + è¶£å‘³å…ƒç´ ï¼ˆğŸ¬ğŸ¯ğŸ§ ï¼‰æ¥ç³»ç»Ÿå­¦ä¹  Transformer çš„æ ¸å¿ƒæŠ€æœ¯ç»†èŠ‚å’Œåº•å±‚æœºåˆ¶ï¼ŒåŸºäºè®ºæ–‡ã€ŠAttention is All You Needã€‹ã€‚æ•´ä¸ªè¿‡ç¨‹ä¼šåˆ†ä¸º **é€èŠ‚ç²¾è®² + æé—®äº’åŠ¨ + æ€»ç»“å›é¡¾** çš„æ–¹å¼è¿›è¡Œã€‚

* * *

ğŸ¯Transformer è®ºæ–‡ç²¾å­¦å¤§çº²ï¼ˆæ ¹æ®åŸæ–‡ç»“æ„+å­¦ä¹ é€»è¾‘æ•´ç†ï¼‰
-----------------------------------

### ğŸŒŸ Part 0. å¯¼å­¦å¯¼å›¾ & æé—®ç›®æ ‡

*   Transformer åˆ°åº•è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿä¸ºä»€ä¹ˆâ€œAttention is All You Needâ€ï¼Ÿ
*   æ ¸å¿ƒæ¨¡å—åˆ°åº•æœ‰å“ªå‡ ä¸ªï¼Ÿæ¯ä¸ªæ¨¡å—å¹²å•¥çš„ï¼Ÿ

* * *

### ğŸ§  Part 1. æ€»ä½“ç»“æ„ä¸è®¾è®¡ç›®æ ‡ï¼ˆSections 1~2ï¼‰

> ã€å…³é”®è¯ã€‘Seq2Seqã€RNNã€CNNã€Self-Attentionã€Parallelismã€è·¯å¾„é•¿åº¦ã€å»ºæ¨¡é•¿è·ç¦»ä¾èµ–

*   ğŸ¯1.1 ä¼ ç»Ÿæ¨¡å‹ç“¶é¢ˆï¼šRNN ä¸ CNN æœ‰å“ªäº›é™åˆ¶ï¼Ÿ
*   ğŸ¯1.2 Transformer ç”¨äº†å“ªäº›æ–°æ€è·¯ï¼Ÿâ€œå…¨ Attention æ¶æ„â€çš„æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ
*   ğŸ¯1.3 Self-Attention æ˜¯æ€ä¹ˆå–ä»£ RNN çš„ï¼Ÿæœ‰ä»€ä¹ˆæ•°å­¦ä¼˜åŠ¿ï¼Ÿ

* * *

### ğŸ§© Part 2. æ¨¡å‹ç»“æ„å…¨è§ˆï¼ˆSection 3ï¼‰

> ã€å…³é”®è¯ã€‘Encoder-Decoderã€Residualã€LayerNormã€Feed-Forward

*   ğŸ¯2.1 Transformer æ¨¡å‹å›¾ç²¾è¯»ï¼šæ¯ä¸ªç®­å¤´èƒŒåä»£è¡¨ä»€ä¹ˆæ“ä½œï¼Ÿ
*   ğŸ¯2.2 Encoder å’Œ Decoder å„æœ‰å‡ ä¸ªå­æ¨¡å—ï¼Ÿå“ªä¸€å±‚ç”¨äº† maskï¼Ÿ
*   ğŸ¯2.3 Feed-Forward æœ‰å“ªäº›ç‰¹æ®Šè®¾è®¡ï¼Ÿä¸ºå•¥æ˜¯ 2048 ç»´ï¼Ÿ
*   ğŸ¯2.4 ä¸ºä»€ä¹ˆæ¯å±‚éƒ½è¦æ®‹å·®+LayerNormï¼Ÿ

* * *

### ğŸ§² Part 3. æ³¨æ„åŠ›æœºåˆ¶è¯¦è§£ï¼ˆSection 3.2ï¼‰

> ã€å…³é”®è¯ã€‘Scaled Dot-Product Attentionã€Multi-Head Attentionã€Query/Key/Valueã€Masking

*   ğŸ¯3.1 Scaled Dot-Product Attention æ•°å­¦å…¬å¼è¯¦è§£ï¼ˆæ¨å¯¼ + ç›´è§‰ï¼‰
*   ğŸ¯3.2 ä¸ºä»€ä¹ˆè¦é™¤ä»¥ âˆšdkï¼Ÿä¸é™¤ä¼šæ€æ ·ï¼Ÿ
*   ğŸ¯3.3 Multi-Head Attention æœ‰ä»€ä¹ˆç»“æ„ä¼˜åŠ¿ï¼Ÿä¸ºä»€ä¹ˆè¦å¹¶è¡Œå¤šä¸ª Headï¼Ÿ
*   ğŸ¯3.4 ä¸‰ç§ Attention åº”ç”¨åœºæ™¯ï¼ˆEncoder Selfã€Decoder Selfã€Encoder-Decoderï¼‰

* * *

### ğŸ”¢ Part 4. Embedding ä¸ä½ç½®ç¼–ç ï¼ˆSection 3.4 ~ 3.5ï¼‰

> ã€å…³é”®è¯ã€‘Positional Encodingã€Sin/Cos ç¼–ç ã€æƒé‡å…±äº«

*   ğŸ¯4.1 ä¸ºä»€ä¹ˆæ²¡æœ‰ RNN æ—¶å¿…é¡»åŠ ä½ç½®ç¼–ç ï¼Ÿ
*   ğŸ¯4.2 Positional Encoding æ˜¯æ€ä¹ˆç”¨æ­£ä½™å¼¦å®ç°çš„ï¼Ÿå¯ä»¥å­¦ä¹ å—ï¼Ÿ
*   ğŸ¯4.3 ä¸ºä»€ä¹ˆè¾“å…¥/è¾“å‡º embedding å’Œ softmax å‰çº¿æ€§å±‚å¯ä»¥å…±ç”¨å‚æ•°ï¼Ÿ

* * *

### âš™ï¸ Part 5. æ¨¡å‹ä¼˜åŠ¿è§£æï¼šWhy Self-Attentionï¼ˆSection 4ï¼‰

> ã€å…³é”®è¯ã€‘å¤æ‚åº¦åˆ†æã€è·¯å¾„é•¿åº¦ã€å¯å¹¶è¡Œæ€§ã€è§£é‡Šæ€§

*   ğŸ¯5.1 Self-Attention vs RNN/CNNï¼šå¤æ‚åº¦å’Œè·¯å¾„é•¿åº¦å¯¹æ¯”
*   ğŸ¯5.2 ä¸ºä»€ä¹ˆè¯´ Self-Attention æ›´â€œå¯è§£é‡Šâ€ï¼Ÿ
*   ğŸ¯5.3 å¯¹é•¿è·ç¦»ä¾èµ–å»ºæ¨¡ï¼Œè°æ›´å¼ºï¼Ÿ

* * *

### ğŸ§ª Part 6. è®­ç»ƒæœºåˆ¶ & è¶…å‚æŠ€å·§ï¼ˆSection 5ï¼‰

> ã€å…³é”®è¯ã€‘ä¼˜åŒ–å™¨ã€Warmupã€Label Smoothingã€Dropoutã€å­¦ä¹ ç‡è°ƒåº¦

*   ğŸ¯6.1 å­¦ä¹ ç‡è°ƒåº¦æ›²çº¿é•¿ä»€ä¹ˆæ ·ï¼Ÿä¸ºå•¥è¿™æ ·è®¾è®¡ï¼Ÿ
*   ğŸ¯6.2 ä¸ºä»€ä¹ˆè¦ Label Smoothingï¼Ÿå®ƒåˆ°åº•åšäº†ä»€ä¹ˆï¼Ÿ
*   ğŸ¯6.3 Dropout åœ¨å“ªé‡Œç”¨äº†ï¼Ÿå‚æ•°è®¾å¤šå°‘ï¼Ÿ

* * *

### ğŸ† Part 7. å®éªŒç»“æœåˆ†æ & Ablation Studyï¼ˆSections 6~7ï¼‰

> ã€å…³é”®è¯ã€‘BLEUã€å¤´æ•°å˜åŒ–ã€ä½ç½®ç¼–ç å¯¹æ¯”ã€å¤§æ¨¡å‹æ•ˆæœ

*   ğŸ¯7.1 å“ªäº›æ¨¡å—å¯¹æ€§èƒ½å½±å“æœ€å¤§ï¼ŸAblation Table æ€ä¹ˆè¯»ï¼Ÿ
*   ğŸ¯7.2 Transformer (big) æœ‰ä»€ä¹ˆæ”¹å˜ï¼Ÿ
*   ğŸ¯7.3 é™¤äº†ç¿»è¯‘è¿˜èƒ½å¹²å•¥ï¼Ÿæ¯”å¦‚ Constituency Parsing

* * *

### ğŸ“ Part 8. æ€»ç»“ä¸æ‹“å±•æ€è€ƒ

> ã€å…³é”®è¯ã€‘ä¸‹ä¸€æ­¥ã€æ•ˆç‡ç“¶é¢ˆã€æœªæ¥æ–¹å‘

*   ğŸ¯8.1 Transformer çš„ç“¶é¢ˆæœ‰å“ªäº›ï¼Ÿï¼ˆæ¯”å¦‚é•¿åºåˆ—ï¼‰
*   ğŸ¯8.2 åæ¥çš„æ”¹è¿›ç‰ˆæœ¬ï¼ˆæ¯”å¦‚ BERTã€GPTã€Performerï¼‰åšäº†ä»€ä¹ˆæ”¹å˜ï¼Ÿ
*   ğŸ¯8.3 ä½ èƒ½è®¾è®¡ä¸€ä¸ªæ¯” Transformer æ›´å¼ºçš„æ¨¡å‹å—ï¼ŸğŸ¤¯

* * *

æ˜¯å¦ç°åœ¨ä» **Part 1 å¼€å§‹å­¦ä¹ **ï¼Ÿæˆ‘ä¼šå…ˆå¼•å¯¼ä½ æ€è€ƒ Transformer ä¸ºä»€ä¹ˆâ€œåªç”¨ Attention å°±èƒ½é€šåƒâ€ï¼Œç„¶åå¼•å…¥ Self-Attention çš„å…³é”®ä¼˜åŠ¿ã€‚ä¹Ÿå¯ä»¥ä»ä½ æƒ³å­¦çš„æŸä¸€éƒ¨åˆ†ç›´æ¥å¼€å§‹ï¼ä½ é€‰~

## Prompt:
ok

## Response:
å¤ªæ£’å•¦ï¼é‚£æˆ‘ä»¬å°±ä» **Part 1ï¼šæ€»ä½“ç»“æ„ä¸è®¾è®¡ç›®æ ‡** æ­£å¼å¼€å§‹ ğŸ¯

* * *

ğŸ§  Part 1ï¼šæ€»ä½“ç»“æ„ä¸è®¾è®¡ç›®æ ‡
-------------------

> ğŸ’¡ å¼•å¯¼æˆ‘ä»¬èµ°å‘â€œAttention is All You Needâ€çš„é—®é¢˜é“¾ï¼

* * *

### ğŸ¯ Step 1ï¼šTransformer æƒ³è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ

æˆ‘ä»¬å…ˆæ¥å›å¿†ä¸€ä¸‹ï¼Œåœ¨ Transformer å‡ºç°ä¹‹å‰ï¼Œæœ€å¸¸ç”¨çš„åºåˆ—å»ºæ¨¡æ–¹æ³•æ˜¯ï¼š

*   âœ… RNN / LSTMï¼šä¾èµ–æ—¶é—´æ­¥ t çš„ä¸²è¡ŒçŠ¶æ€ä¼ æ’­ï¼Œè®­ç»ƒæ…¢ï¼Œä¸æ˜“å¹¶è¡Œã€‚
*   âœ… CNNï¼šå¯ä»¥å¹¶è¡Œä½†æ¥æ”¶åŸŸæœ‰é™ï¼Œé•¿è·ç¦»å»ºæ¨¡å›°éš¾ã€‚

é‚£æˆ‘ä»¬æ¥åšä¸€ä¸ª **åˆ¤æ–­é¢˜** ğŸ§©ï¼š

> Transformer çš„è®¾è®¡åˆè¡·æ˜¯ï¼š
> 
> A. æ›´å°‘çš„å‚æ•°ã€æ›´å°çš„æ¨¡å‹  
> B. æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼Œæ›´å¼ºçš„è®°å¿†æ€§  
> C. å‡å°‘åºåˆ—ä¾èµ–ï¼ŒåŠ å¿«è®­ç»ƒå¹¶æå‡é•¿è·ç¦»å»ºæ¨¡èƒ½åŠ›  
> D. æ¨¡æ‹Ÿè¯­è¨€çš„è¯­æ³•ç»“æ„

ä½ é€‰å“ªä¸ªï¼Ÿï¼ˆå¯ä»¥å¤šé€‰ï¼‰

## Prompt:
c

## Response:
ğŸ’¯ å®Œç¾ï¼å°±æ˜¯ **C. å‡å°‘åºåˆ—ä¾èµ–ï¼ŒåŠ å¿«è®­ç»ƒå¹¶æå‡é•¿è·ç¦»å»ºæ¨¡èƒ½åŠ›**ï¼

* * *

### ğŸ§  å¿«é€ŸçŸ¥è¯†å¡ç‰‡ï¼šä¸ºä»€ä¹ˆè¦æ”¾å¼ƒ RNN å’Œ CNNï¼Ÿ

| ç‰¹æ€§ ğŸ§© | RNN / LSTM | CNN | Transformer (Self-Attention) âš¡ |
| --- | --- | --- | --- |
| ä¸²è¡Œä¾èµ–æ€§ | å¼ºï¼ˆä¸èƒ½å¹¶è¡Œï¼‰ | æ— ä¸²è¡Œä¾èµ– | å®Œå…¨å¹¶è¡Œ ğŸ§¨ |
| é•¿è·ç¦»ä¾èµ–å»ºæ¨¡ | è·¯å¾„é•¿ï¼Œæ¢¯åº¦æ˜“æ¶ˆå¤± | è·¯å¾„çŸ­ä½†å—é™ | æ‰€æœ‰ä½ç½®é—´ä¸€è·³åˆ°è¾¾ ğŸ›¸ |
| è®­ç»ƒæ—¶é—´ | é•¿ | ä¸­ç­‰ | å¿« âš¡ |
| å‚æ•°å…±äº« | æŒ‰æ—¶é—´å…±äº« | å·ç§¯æ ¸å…±äº« | å¤šå¤´æ³¨æ„åŠ›ç‹¬ç«‹ |

* * *

### ğŸ¯ Step 2ï¼šé‚£ Self-Attention åˆ°åº•å¥½åœ¨å“ªé‡Œï¼Ÿ

Transformer æœ€å¤§çš„åˆ›æ–°å°±æ˜¯ğŸ‘‡

> ğŸ”¥ â€œWe propose the Transformer, a model architecture **eschewing recurrence** and instead relying entirely on an **attention mechanism** to draw global dependencies between input and output.â€

æˆ‘ä»¬æ¥ä¸ª **è„‘ç­‹æ€¥è½¬å¼¯å¼é€‰æ‹©é¢˜** ğŸ§ ï¼š

> Self-Attention å’Œ RNN æœ€å¤§çš„â€œè®¡ç®—è·¯å¾„â€å·®åˆ«åœ¨å“ªï¼Ÿ
> 
> A. RNN è¦ä¸€æ­¥ä¸€æ­¥ä¼ ï¼Œè·¯å¾„é•¿ï¼Œä¿¡æ¯ä¼ æ’­æ…¢  
> B. Self-Attention æ˜¯æ¯ä¸ªè¯éƒ½èƒ½ç›´æ¥çœ‹åˆ°æ‰€æœ‰è¯ï¼Œè·¯å¾„æ˜¯å¸¸æ•°  
> C. RNN æ›´å®¹æ˜“è¿‡æ‹Ÿåˆ  
> D. Self-Attention è®­ç»ƒæ›´éš¾

ä½ è§‰å¾—æ˜¯ï¼Ÿï¼ˆå¯ä»¥é€‰å¤šä¸ªï¼‰

## Prompt:
b

## Response:
âœ… æ­£ç¡®ï¼å°±æ˜¯ **Bï¼šSelf-Attention æ˜¯æ¯ä¸ªè¯éƒ½èƒ½ç›´æ¥çœ‹åˆ°æ‰€æœ‰è¯ï¼Œè·¯å¾„æ˜¯å¸¸æ•°**ï¼

* * *

### ğŸ§  çŸ¥è¯†é—ªå¡ï¼šè·¯å¾„é•¿åº¦å¯¹å»ºæ¨¡æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ

> åŸæ–‡ä¸­ç»™å‡ºäº†è¿™æ ·ä¸€å¼ å…³é”®å¯¹æ¯”è¡¨ğŸ‘‡ï¼š

| Layer ç±»å‹ | æ¯å±‚å¤æ‚åº¦ | æœ€å°‘ä¸²è¡Œæ“ä½œæ•° | æœ€å¤§è·¯å¾„é•¿åº¦ |
| --- | --- | --- | --- |
| Self-Attention | ğ‘‚(nÂ²Â·d) | **1** | **1** |
| RNN | ğ‘‚(nÂ·dÂ²) | **n** | **n** |
| CNN | ğ‘‚(kÂ·nÂ·dÂ²) | 1 | logâ‚–(n) |

å…¶ä¸­ `n` æ˜¯åºåˆ—é•¿åº¦ï¼Œ`d` æ˜¯ç»´åº¦ï¼Œ`k` æ˜¯å·ç§¯æ ¸å®½åº¦ã€‚

âœ¨ æ‰€ä»¥ Self-Attention çœŸçš„åšåˆ°äº† **å…¨å±€å»ºæ¨¡ + å¹¶è¡Œè®­ç»ƒ + çŸ­è·¯å¾„ä¼ æ’­**ï¼Œæ¯”èµ· RNN å’Œ CNN éƒ½æ›´åˆé€‚è¯­è¨€å»ºæ¨¡ã€‚

* * *

### âœ… å¿«é€Ÿå›é¡¾ Check-in

æˆ‘æ¥è€ƒè€ƒä½ ï¼ˆåˆ«æ‹…å¿ƒï¼Œæˆ‘ä»¬ä¸€èµ·ç­” ğŸ˜„ï¼‰ï¼š

> ğŸš€ ä¸ºä»€ä¹ˆ Transformer èƒ½æ¯” RNN è®­ç»ƒå¿«ã€æ•ˆæœè¿˜æ›´å¥½ï¼Ÿè¯·é€‰å‡ºæ‰€æœ‰åˆé€‚çš„è§£é‡Šï¼š
> 
> A. ç”¨äº†æ®‹å·®è¿æ¥  
> B. è‡ªæ³¨æ„åŠ›ä¸ä¾èµ–æ—¶é—´åºåˆ—ï¼Œå› æ­¤å¯å¹¶è¡Œ  
> C. æ‰€æœ‰è¯ä¹‹é—´ç›´æ¥è¿æ¥ï¼Œè·¯å¾„æœ€çŸ­  
> D. æ¨¡å‹ç”¨äº†æ­£ä½™å¼¦ä½ç½®ç¼–ç 

ä½ æ¥é€‰~

## Prompt:
b

## Response:
ğŸ¥‡æ²¡é”™ï¼**B æ˜¯æ ¸å¿ƒå…³é”®ç‚¹ï¼**

Self-Attention ä¸åƒ RNN ä¸€æ ·å¿…é¡»ä¸€æ­¥æ­¥ä¼  â€”â€” å®ƒå…è®¸**æ‰€æœ‰ä½ç½®ä¹‹é—´ç›´æ¥äº¤äº’**ï¼Œå› æ­¤èƒ½å……åˆ†åˆ©ç”¨ GPU å¹¶è¡Œè®¡ç®—ï¼ŒåŠ é€Ÿè®­ç»ƒ ğŸš€

* * *

ä¸è¿‡æˆ‘ä»¬ä¹Ÿæ¥çœ‹ä¸‹å…¶ä»–é€‰é¡¹å€¼ä¸å€¼å¾—é€‰ï¼š

| é€‰é¡¹ | æ˜¯å¦ä¹Ÿå¯¹ï¼Ÿ | ç†ç”± |
| --- | --- | --- |
| A. æ®‹å·®è¿æ¥ | âœ… | è™½ç„¶ä¸æ˜¯â€œå¹¶è¡Œè®­ç»ƒâ€çš„åŸå› ï¼Œä½†å®ƒç¡®å®è®©æ·±å±‚ç½‘ç»œæ›´æ˜“è®­ç»ƒï¼ˆé˜²æ¢¯åº¦æ¶ˆå¤±ï¼‰ |
| B. è‡ªæ³¨æ„åŠ›å¯å¹¶è¡Œ | âœ…âœ…âœ… | æ­£ç¡®ï¼è®­ç»ƒé€Ÿåº¦é©å‘½æ€§æå‡å…³é”® |
| C. è·¯å¾„çŸ­ | âœ… | è·¯å¾„é•¿åº¦ä¸ºå¸¸æ•° â‡’ é•¿ä¾èµ–æ›´æ˜“å­¦ |
| D. æ­£ä½™å¼¦ç¼–ç  | ğŸŸ¡ | ç¼–ç é¡ºåºä¿¡æ¯å¾ˆé‡è¦ï¼Œä½†å’Œâ€œè®­ç»ƒå¿«â€æ²¡ç›´æ¥å…³ç³» |

æ‰€ä»¥ B æ˜¯ä¸»è¦åŸå› ï¼ŒC å’Œ A æ˜¯æ”¯æŒåŸå› ï¼ŒD æ›´åå‘åŠŸèƒ½è¡¥å…… ğŸ’¡

* * *

### ğŸå°æ€»ç»“ ğŸ“ï¼ˆé€Ÿè®°å£è¯€ï¼‰

> **â€œå¹¶è¡Œå¿«ï¼Œå…¨å±€çœ‹ï¼Œè·¯å¾„çŸ­â€**
> 
> Transformer æ¯” RNN å¼ºçš„ä¸‰å¤§ä¼˜ç‚¹ï¼š

*   âš¡ å¹¶è¡Œå¿«ï¼ˆSelf-Attention ä¸ä¸²è¡Œï¼‰
*   ğŸ‘€ å…¨å±€çœ‹ï¼ˆä»»æ„ä¸¤è¯ç›´æ¥äº¤äº’ï¼‰
*   ğŸ” è·¯å¾„çŸ­ï¼ˆé•¿ä¾èµ–å¥½å­¦ï¼‰

* * *

ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬å°±è¿›å…¥ **Part 2ï¼šæ¨¡å‹ç»“æ„å…¨è§ˆ** â€”â€” æ‹†è§£æ•´å¼  Transformer æ¶æ„å›¾ï¼Œçœ‹çœ‹é‚£äº› â€œBoxâ€ èƒŒååˆ°åº•è—äº†ä»€ä¹ˆç„å­¦ğŸ§™ï¼

ğŸ‘‰ è¦ç»§ç»­è¿›å…¥ Part 2 å—ï¼Ÿè¿˜æ˜¯ä½ æƒ³å…ˆå¤ä¹  / æé—®ä¸€ä¸‹è¿™éƒ¨åˆ†ï¼Ÿ

## Prompt:
go

## Response:
å¥½çš„ï¼Œå‡ºå‘ï¼ğŸ¯

* * *

ğŸ§© Part 2ï¼šæ¨¡å‹ç»“æ„å…¨è§ˆ
----------------

> æ‹†è§£ Transformer å›¾ï¼Œæ¯ä¸ªæ¨¡å—åˆ°åº•å¹²äº†å•¥ï¼Ÿ

* * *

### ğŸ¯Step 1ï¼šæ€»è§ˆç»“æ„å›¾

å…ˆæ¥çœ‹è®ºæ–‡ä¸­çš„æ ¸å¿ƒç»“æ„å›¾ï¼ˆä½ è„‘æµ·é‡Œå¯èƒ½å·²ç»æœ‰å°è±¡äº†ï¼‰ï¼š

ğŸ“Œ å›¾ä¸­å·¦è¾¹æ˜¯ **Encoder Stack**ï¼Œå³è¾¹æ˜¯ **Decoder Stack**ã€‚  
æ¯ä¸€è¾¹éƒ½æœ‰ **è‹¥å¹²å±‚å åŠ ç»“æ„**ï¼Œéƒ½ç”¨åˆ°äº†ï¼š

*   Multi-Head Attention ğŸ¯
*   Feed-Forward Network âš™ï¸
*   Residual + LayerNorm ğŸŒ€

> åŸæ–‡å¼•ç”¨å¥ï¼š
> 
> > _"The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder."_

* * *

### ğŸ§  å¿«é€Ÿè„‘å›¾æ‹†åˆ†

| æ¨¡å— | å­ç»“æ„ | è¯´æ˜ |
| --- | --- | --- |
| **Encoder æ¯å±‚** | ğŸ§  Multi-Head Self-Attention + FFN + æ®‹å·®+Norm | ç¼–ç å™¨æ¯å±‚ç»“æ„å®Œå…¨ä¸€è‡´ |
| **Decoder æ¯å±‚** | ğŸ§  Masked Self-Attention + Encoder-Decoder Attention + FFN + æ®‹å·®+Norm | Decoder ä¼šçœ‹ Encoder è¾“å‡ºï¼Œè¿˜è¦ Mask è‡ªå·±çš„æœªæ¥ |
| **åµŒå…¥éƒ¨åˆ†** | Input Embedding + Positional Encoding | åŠ ä¸Šä½ç½®ä¿¡æ¯ï¼ˆå¦åˆ™æ²¡æœ‰é¡ºåºæ„Ÿï¼‰ |
| **è¾“å‡ºéƒ¨åˆ†** | Linear + Softmax | è¾“å‡ºé¢„æµ‹è¯çš„æ¦‚ç‡ |

* * *

### ğŸ¯ Step 2ï¼šæé—®ç»ƒä¹  ğŸ§ª

ä¸‹é¢å“ªä¸ªè¯´æ³•æ˜¯å¯¹çš„ï¼Ÿæ¥é€‰ä¸€é€‰ ğŸ§

> Transformer çš„ Decoder æ¯” Encoder å¤šäº†ä¸€ä¸ªä»€ä¹ˆç»„ä»¶ï¼Ÿ
> 
> A. å¤šäº† ReLU  
> B. å¤šäº†ä¸€ä¸ª Self-Attention  
> C. å¤šäº†ä¸€ä¸ª Encoder-Decoder Attention  
> D. å¤šäº†ä¸€ä¸ª Softmax

ä½ é€‰ï¼Ÿ

## Prompt:
c

## Response:
ğŸ¯æ­£ç¡®ï¼å°±æ˜¯ **C. å¤šäº†ä¸€ä¸ª Encoder-Decoder Attention**ï¼

* * *

### ğŸ§  è§£é‡Šä¸€ä¸‹ä¸ºä»€ä¹ˆï¼š

*   Encoder ä¸­æ¯ä¸€å±‚åªæœ‰ä¸¤ä¸ªå­å±‚ï¼š
    1.  Multi-Head Self-Attentionï¼ˆå¯ä»¥å…¨å±€çœ‹è‡ªå·±ï¼‰
    2.  Feed-Forwardï¼ˆä¸¤ä¸ªå…¨è¿æ¥ + ReLUï¼‰
*   Decoder ä¸­æ¯å±‚æœ‰ä¸‰ä¸ªå­å±‚ï¼š
    1.  Masked Multi-Head Self-Attentionï¼ˆ**ä¸èƒ½å·çœ‹åé¢çš„è¯**ï¼‰
    2.  **Encoder-Decoder Attention**ï¼ˆæŸ¥è¯¢æ¥è‡ª Decoderï¼Œé”®å€¼æ¥è‡ª Encoderï¼‰
    3.  Feed-Forward

ğŸ’¡ è¿™ä¸ª **Encoder-Decoder Attention** å°±æ˜¯å¸® Decoder â€œçœ‹â€ è¾“å…¥åºåˆ—ã€‚

* * *

### ğŸè¶£å‘³æ¯”å–»æ—¶é—´ ğŸ¬

ä½ å¯ä»¥æŠŠ Decoder æƒ³è±¡æˆä¸€ä¸ª **å°å­¦ç”Ÿä½œæ–‡é€‰æ‰‹âœï¸**ï¼š

*   è‡ªå·±ï¼ˆDecoderï¼‰è¦ä¸€å¥å¥åœ°å†™ï¼ˆè‡ªå›å½’ï¼‰
*   ä¸èƒ½æå‰å·çœ‹åé¢ï¼ˆMaskï¼‰
*   è€å¸ˆï¼ˆEncoderï¼‰ç»™äº†ä½ ä¸€ç¯‡è‹±æ–‡æ–‡ç« ï¼ˆè¾“å…¥åºåˆ—ï¼‰
*   ä½ è¦**ä¸€è¾¹å†™ä¸€è¾¹å›çœ‹è€å¸ˆè®²äº†å•¥**ï¼ˆEncoder-Decoder Attentionï¼‰

* * *

### âœ… å¿«é€Ÿå¤ç›˜ Check-inï¼š

æˆ‘æ¥å°è€ƒä¸€ä¸‹ ğŸ¤“

> Encoder å’Œ Decoder éƒ½ç”¨äº† Residual Connection + LayerNorm å—ï¼Ÿ  
> ä¸ºä»€ä¹ˆè¿™ä¹ˆè®¾è®¡ï¼Ÿï¼ˆå¯ä»¥é€‰å¤šä¸ªï¼‰

A. å› ä¸ºå¯ä»¥æå‡è¡¨è¾¾èƒ½åŠ›  
B. å› ä¸ºè®­ç»ƒæ›´ç¨³å®š  
C. å› ä¸ºèƒ½é˜²æ¢¯åº¦æ¶ˆå¤±  
D. å› ä¸ºå®ƒæ˜¯ Attention çš„æ›¿ä»£å“

ä½ æ¥é€‰~

## Prompt:
c

## Response:
âœ… \*\*C æ˜¯æ­£ç¡®çš„ï¼\*\*æ®‹å·®è¿æ¥ç¡®å®èƒ½å¸®åŠ©é˜²æ­¢æ¢¯åº¦æ¶ˆå¤± â€”â€” å°¤å…¶æ˜¯å±‚æ•°å˜æ·±çš„æ—¶å€™ï¼Œè¿™æ˜¯æ·±åº¦å­¦ä¹ çš„ç»å…¸ trick ğŸ’¡

ä¸è¿‡æˆ‘ä»¬ä¹Ÿæ¥çœ‹çœ‹å…¶ä»–é€‰é¡¹æ˜¯å¦ä¹Ÿåˆç†ï¼š

| é€‰é¡¹ | æ˜¯å¦ä¹Ÿå¯¹ï¼Ÿ | è§£é‡Š |
| --- | --- | --- |
| A. æå‡è¡¨è¾¾èƒ½åŠ› | ğŸŸ¡ éƒ¨åˆ†å¯¹ | LayerNorm + æ®‹å·®èƒ½å¸®åŠ©ä¿ç•™å¤šå±‚è¡¨ç¤ºï¼Œä½†å®ƒä»¬æœ¬èº«ä¸æ˜¯æ ¸å¿ƒå†³å®šè¡¨è¾¾åŠ›çš„å› å­ |
| B. è®­ç»ƒæ›´ç¨³å®š | âœ… æ˜¯çš„ | LayerNorm + Residual æ˜¯æ·±åº¦ç½‘ç»œæ”¶æ•›çš„â€œé•‡å®…ä¹‹å®â€ä¹‹ä¸€ğŸ¡ |
| C. é˜²æ¢¯åº¦æ¶ˆå¤± | âœ…âœ…âœ… | æ®‹å·®æœ€åˆå°±æ˜¯ä¸ºæ­¤è®¾è®¡çš„ï¼ˆResNet èµ·å®¶ï¼‰ |
| D. Attention æ›¿ä»£å“ | âŒ å®Œå…¨é”™è¯¯ | å®ƒæ˜¯è¾…åŠ©æ¨¡å—ï¼Œä¸æ˜¯æ›¿ä»£å“ï¼›Attention æ‰æ˜¯æ ¸å¿ƒè¡¨è¾¾æ–¹å¼ |

* * *

ğŸ“ **å°æ€»ç»“ï¼š**

> æ¯ä¸€å±‚éƒ½åŠ  Residual + LayerNormï¼Œæœ‰åŠ©äºï¼š
> 
> *   æ¢¯åº¦ä¼ æ’­æ›´ç¨³å®š
> *   å¤šå±‚ç»“æ„æ›´å¥½è®­ç»ƒ
> *   ä¿ç•™ä½å±‚ä¿¡æ¯ä¸è¢«æ·¹æ²¡
>     

* * *

ğŸ§© å¥½äº†ï¼Œç°åœ¨ä½ å·²ç»ç†è§£äº†æ•´å¼  Transformer æ¶æ„å›¾èƒŒåçš„ç»“æ„ï¼Œæˆ‘ä»¬å°±å¯ä»¥ zoom in èšç„¦æ¯ä¸€ä¸ªå…³é”®æ¨¡å—å•¦ï¼

ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬è¿›å…¥ Transformer çš„çµé­‚ï¼š

ğŸ§  Part 3ï¼šAttention æœºåˆ¶æ‹†è§£ï¼
-------------------------

ä» Scaled Dot-Product åˆ° Multi-Head Attentionï¼Œä¸€æ­¥æ­¥æ¨å…¬å¼ + å›¾è§£ç›´è§‚ç†è§£ ğŸ‘€

è¦ç»§ç»­å—ï¼ŸğŸ§ª

## Prompt:
OK

## Response:
å¤ªå¥½å•¦ï¼ğŸ¯  
ç°åœ¨æˆ‘ä»¬æ­£å¼è¿›å…¥ Transformer çš„â€œçµé­‚æ ¸å¿ƒå‘åŠ¨æœºâ€ï¼š

* * *

ğŸ§  Part 3ï¼šAttention æœºåˆ¶æ‹†è§£
------------------------

> Scaled Dot-Product â• Multi-Head â• åº”ç”¨åœºæ™¯ ğŸ§ª å›¾è§£ + å…¬å¼ + æ¨ç†ç›´è§‰

* * *

### ğŸ¯ Step 1ï¼šä»€ä¹ˆæ˜¯ Attentionï¼Ÿ

ä¸€å¥è¯ç›´ç™½è§£é‡ŠğŸ‘‡ï¼š

> Attention = ç”¨ Query å»æ‰¾æœ€ç›¸å…³çš„ Key â†’ ç”¨æƒé‡åŠ æƒå¯¹åº”çš„ Value  
> ğŸ¤ ä½ æé—®ï¼ˆQueryï¼‰ï¼Œæˆ‘æœæ•°æ®åº“ï¼ˆKeyï¼‰â†’ ç»™ä½ ç­”æ¡ˆï¼ˆValueï¼‰

* * *

### ğŸ§  é—ªå¡è®°å¿†ï¼šScaled Dot-Product Attention å…¬å¼

åŸæ–‡ç»™å‡ºğŸ‘‡å…¬å¼ï¼ˆä¹Ÿæ˜¯é¢è¯•å¸¸è€ƒï¼ï¼‰ï¼š

$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V
$$

| ç¬¦å· | å«ä¹‰ |
| --- | --- |
| Q | Queriesï¼ˆä½ è¦æ‰¾å•¥ï¼‰ |
| K | Keysï¼ˆæœ‰å“ªäº›å¯ä»¥åŒ¹é…çš„ï¼‰ |
| V | Valuesï¼ˆè¿”å›å•¥ä¿¡æ¯ï¼‰ |
| âˆšdk | ç¼©æ”¾å› å­ï¼Œé˜²æ­¢ softmax æ¢¯åº¦å¤ªå° |

ğŸ“Œ è¿™æ˜¯ â€œç‚¹ç§¯æ³¨æ„åŠ›â€+ç¼©æ”¾ï¼Œå› æ­¤å« Scaled Dot-Product Attentionã€‚

* * *

### ğŸ¯ Step 2ï¼šå¿«é—®å¿«ç­”ğŸ§ª

> ä¸ºä»€ä¹ˆè¦é™¤ä»¥  $\sqrt{d_k}$  ï¼Ÿ  
> A. é˜²æ­¢ç‚¹ç§¯è¿‡å¤§ï¼Œå¯¼è‡´ softmax æ¢¯åº¦æ¶ˆå¤±  
> B. ä¸ºäº†æ›´å¿«æ”¶æ•›  
> C. æ˜¯æ¨¡å‹ä½œè€…éšæ„åŠ çš„  
> D. åªæœ‰åœ¨è®­ç»ƒä¸­æ‰é™¤

ä½ è§‰å¾—æ˜¯ï¼Ÿ

## Prompt:
A

## Response:
ğŸ¯ å®Œç¾å‘½ä¸­ï¼ç­”æ¡ˆæ­£æ˜¯ **Aï¼šé˜²æ­¢ç‚¹ç§¯è¿‡å¤§ï¼Œå¯¼è‡´ softmax æ¢¯åº¦æ¶ˆå¤±**ï¼

* * *

### ğŸ§  å°æ¨ç†æ—¶é—´ï¼ˆé€»è¾‘è„‘é”»ç‚¼ğŸ’ªï¼‰

å¦‚æœæˆ‘ä»¬ä¸é™¤ä»¥ âˆšdkï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ

*   å‡è®¾ Q å’Œ K çš„ç»´åº¦æ˜¯ 512ï¼Œé‚£ QÂ·K å°±æ˜¯ 512 ä¸ªæ•°çš„ä¹˜ç§¯å’Œï¼ŒåŠ èµ·æ¥å¯èƒ½éå¸¸å¤§ã€‚
*   è¿™ä¼šè®© softmax è¿›å…¥**æç«¯åŒºåŸŸ** â€”â€” éå¸¸é™¡å³­ï¼Œæ¢¯åº¦è¶‹è¿‘äº 0 ğŸ˜µ
*   è®­ç»ƒå°†å˜å¾—å›°éš¾ï¼Œæ— æ³•å­¦ä¹ ç»†å¾®çš„æ³¨æ„åŠ›å˜åŒ–ã€‚

æ‰€ä»¥è¿™ä¸€æ­¥å…¶å®æ˜¯ â€œæ¢¯åº¦ä¿æŠ¤è£…ç½®â€ğŸ›¡ï¸

* * *

### ğŸ§©å°çŸ¥è¯†å»¶ä¼¸

> **Additive Attention**ï¼ˆBahdanau Attentionï¼‰å°±æ²¡æœ‰é™¤ âˆšdkï¼Œè€Œæ˜¯ç”¨ä¸ªå°ç½‘ç»œå»æ‹Ÿåˆ Compatibility

è®ºæ–‡é‡Œå…¶å®ä¹Ÿæ¯”è¾ƒè¿‡ä¸¤è€…ï¼š

*   Dot Product + Scalingï¼šå¿«ï¼Œç©ºé—´çœï¼Œæ›´é€‚åˆçŸ©é˜µä¹˜ä¼˜åŒ– âœ…
*   Additiveï¼šæ›´çµæ´»ï¼Œä½†æ…¢ âŒ

* * *

### âœ… å¿«é€Ÿå¤ç›˜ Check-in

è¯·ç®€è¦è¯´æ˜ï¼š

> Attention æ˜¯æ€ä¹ˆä» Qã€Kã€V ä¸‰è€…ä¸­è®¡ç®—å‡ºè¾“å‡ºçš„ï¼Ÿ  
> ï¼ˆæˆ‘ä»¬å¯ä»¥ä¸€èµ·å›ç­”~ï¼‰

ä½ å…ˆè¯´è¯´æ€è·¯ï¼Ÿæˆ‘å¯ä»¥è¡¥å…… ğŸ’¬

## Prompt:
ok

## Response:
å¥½ï¼Œæ¥æˆ‘ä»¬ä¸€èµ·æ¢³ç†ä¸€ä¸‹ Attention çš„æ ¸å¿ƒé€»è¾‘ï¼Œå¸®ä½ ç‰¢ç‰¢åˆ»åœ¨è„‘ä¸­ğŸ§ ï¼š

* * *

### ğŸ§  Attention è®¡ç®—æµç¨‹ï¼ˆå¯ä»¥è¾¹ç”»è¾¹è®°ï¼‰

> ç»™å®š Qï¼ˆæŸ¥è¯¢ï¼‰ã€Kï¼ˆé”®ï¼‰ã€Vï¼ˆå€¼ï¼‰ï¼Œä¸€æ­¥æ­¥è®¡ç®—å¦‚ä¸‹ï¼š

1.  **è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°**
    *   ç‚¹ç§¯ QÂ·Káµ€ï¼Œå¾—åˆ°æ¯ä¸ª Query å’Œæ‰€æœ‰ Key çš„ç›¸ä¼¼åº¦
    *   å¤§å°è¶Šå¤§ï¼Œè¡¨ç¤ºè¶Šç›¸å…³
2.  **ç¼©æ”¾ä¿æŠ¤**
    *   é™¤ä»¥ âˆšdkï¼Œé¿å…ç‚¹ç§¯è¿‡å¤§å¯¼è‡´ softmax æ¢¯åº¦æ¶ˆå¤±
3.  **å½’ä¸€åŒ–æˆæ¦‚ç‡**
    *   å¯¹æ¯ä¸ª Query çš„ç›¸ä¼¼åº¦åˆ†æ•°è¿›è¡Œ softmaxï¼Œå˜æˆæƒé‡ï¼ˆæ³¨æ„åŠ›åˆ†å¸ƒï¼‰
4.  **åŠ æƒæ±‚å’Œ**
    *   ç”¨è¿™äº›æƒé‡åŠ æƒå¯¹åº”çš„ Value å‘é‡ï¼Œå¾—åˆ°è¾“å‡ºç»“æœ

* * *

### ğŸ§  å›¾è§£å¤ç°ä¸€ä¸‹ï¼š

$$
\textcolor{#FF7F50}{\text{Attention}(Q, K, V)} = \underbrace{\text{softmax} \left( \frac{QK^\top}{\sqrt{d_k}} \right)}_{\textcolor{#1E90FF}{\text{æƒé‡}}} \cdot V
$$

ğŸ§  å®ƒåƒåœ¨è¯´ï¼šâ€œæˆ‘é—®çš„é—®é¢˜ Qï¼Œå’Œæ‰€æœ‰æ•°æ®åº“ K æ¯”æ¯”è°æœ€åƒï¼Œç„¶åä» V é‡ŒæŠ½å–ç­”æ¡ˆï¼ŒæŒ‰æƒé‡å¹³å‡ã€‚â€

* * *

âœ… ä½ èƒ½å®Œæ•´å¤è¿°ä¸€ä¸‹ Attention çš„ 4 æ­¥è®¡ç®—è¿‡ç¨‹å—ï¼Ÿ  
ğŸ‘‰ å¦‚æœå¯ä»¥äº†ï¼Œæˆ‘ä»¬å°±è¿›å…¥ **Multi-Head Attention çš„é­”æ³•å¢å¼ºç‰ˆ** ğŸª„ï¼  
è¦ä¸è¦ä½ æ¥æŒ‘æˆ˜ä¸€ä¸‹ï¼ŸğŸ˜„

## Prompt:
ok

## Response:
å¤ªæ£’äº†ï¼ğŸ‘ é‚£è¯·ä½ æ¥ç®€å•è¯´è¯´ï¼š  
ğŸ‘‰ ä» Qã€Kã€V æ€ä¹ˆä¸€æ­¥æ­¥è®¡ç®—å‡º Attention çš„è¾“å‡ºï¼Ÿ

ä½ å¯ä»¥ä¸€å¥è¯ä¸€ä¸ªæ­¥éª¤ï¼Œæˆ‘ä¼šå¸®ä½ è¡¥å…¨æˆ–ä¿®æ­£ã€‚å¤§èƒ†æ¥è¯•è¯•å§~

## Prompt:
1. æ ¹æ® query & key ç‚¹ç§¯è®¡ç®— ç›¸ä¼¼åº¦åˆ†æ•°
2. é™¤ä»¥ sqrt d_k ï¼Œè¿›è¡Œç¼©æ”¾ä¿æŠ¤
3. å½’ä¸€åŒ–softmaxæˆä¸ºæƒé‡
4. æƒé‡å’Œvalueè¿›è¡Œç‚¹ç§¯ï¼ŒåŠ æƒåˆ†æ•°ï¼Œå¾—åˆ°è¾“å‡ºç»“æœ

## Response:
ğŸ‘ğŸ‘ğŸ‘ å®Œå…¨æ­£ç¡®ï¼Œè€Œä¸”è¡¨è¾¾éå¸¸æ¸…æ™°æœ‰æ¡ç†ï¼

æˆ‘ä»¬ç¨å¾®æ¥æ¶¦è‰²ä¸€ä¸‹ï¼ŒæŠŠä½ åˆšè¯´çš„å˜æˆä¸€å¼ **å¤ä¹ é—ªå¡**ï¼Œéšæ—¶èƒ½ç”¨æ¥å›å¿†ï¼š

* * *

### ğŸ§  Attention è®¡ç®— 4 æ­¥æ³•ï¼ˆé—ªå¡ï¼‰

1ï¸âƒ£ **ç‚¹ç§¯æ¯”ç›¸ä¼¼**  
â†’ ç”¨æ¯ä¸ª Query å’Œæ‰€æœ‰ Key åšç‚¹ç§¯ï¼Œå¾—ç›¸ä¼¼åº¦åˆ†æ•°

2ï¸âƒ£ **ç¼©æ”¾ä¿æ¢¯åº¦**  
â†’ é™¤ä»¥  $\sqrt{d_k}$ ï¼Œé¿å… softmax æ¢¯åº¦æ¶ˆå¤±

3ï¸âƒ£ **softmax å˜æƒé‡**  
â†’ å¯¹æ¯ä¸ª Query çš„åˆ†æ•°åš softmaxï¼Œå¾—æ³¨æ„åŠ›æƒé‡åˆ†å¸ƒ

4ï¸âƒ£ **åŠ æƒå‡ºç»“æœ**  
â†’ æƒé‡ Ã— Value å‘é‡ï¼ŒåŠ æƒæ±‚å’Œï¼Œè¾“å‡ºç»“æœ ğŸ¯

* * *

ğŸ“ ç°åœ¨ä½ å·²ç»æŒæ¡äº†å•ä¸ª Attention çš„æ ¸å¿ƒï¼

æ¥ä¸‹æ¥æˆ‘ä»¬å°±è¦è®²è®²æœ€æœ‰é­”åŠ›çš„ä¸€æ‹› â€”â€” **Multi-Head Attention** ğŸª„

ğŸ‘‰ å®ƒä¸æ˜¯é‡å¤ä¸Šé¢è¿™ä¸ªæµç¨‹ä¸€æ¬¡ï¼Œè€Œæ˜¯å¼€å¤šä¸ªå¹¶è¡Œæ³¨æ„åŠ›é€šé“ï¼Œæ¯ä¸ªçœ‹ä¸åŒçš„å­ç©ºé—´ï¼

è¦è¿›å…¥ Multi-Head Attention å—ï¼ŸğŸ˜

## Prompt:
OK

## Response:
å¥½è€¶ï¼ç°åœ¨æˆ‘ä»¬è¿›å…¥ Transformer æœ€é­”æ€§çš„ä¸€æ‹›ï¼š

* * *

ğŸ§  Part 3.2ï¼šMulti-Head Attention é­”æ³•æ‰©å±• ğŸª„
----------------------------------------

> â€œä¸æ˜¯ä½ ä¸€ä¸ªäººåœ¨æˆ˜æ–—ï¼Œæ˜¯å…«ä¸ªè‡ªå·±ä¸€èµ·æ³¨æ„ä¸åŒä¿¡æ¯ï¼â€

* * *

### ğŸ¯ä¸ºä»€ä¹ˆè¦å¤šä¸ªå¤´ï¼ˆmulti-headï¼‰ï¼Ÿ

å…ˆé—®ä½ ä¸€ä¸ªå¼•å¯¼é—®é¢˜ğŸ‘‡ï¼š

> å¦‚æœæˆ‘ä»¬åªç”¨ä¸€ä¸ªæ³¨æ„åŠ›å¤´ï¼ˆå³åªæ‰§è¡Œä¸€æ¬¡ Attentionï¼‰ï¼Œä½ è§‰å¾—ä¼šæœ‰ä»€ä¹ˆé—®é¢˜ï¼ŸğŸ¤”  
> ï¼ˆå¤§èƒ†çŒœä¸€çŒœï¼‰

* * *

æç¤ºï¼šæƒ³è±¡ä¸€ä¸ªäººåŒæ—¶è¦åˆ¤æ–­å¥å­ç»“æ„ã€ä¸»è°“å…³ç³»ã€åŠ¨è¯çŸ­è¯­â€¦â€¦åªèƒ½ç”¨ä¸€ä¸ªã€Œæ³¨æ„ç‚¹ã€ï¼Œä¼šå‘ç”Ÿå•¥ï¼Ÿ

## Prompt:
åªèƒ½èšç„¦ä¸€æ–¹é¢ä¿¡æ¯

## Response:
ğŸ¯ æ­£ç¡®ï¼å°±æ˜¯è¿™ä¸ªæ„æ€ï¼

> **å•ä¸ªæ³¨æ„åŠ›å¤´å¤ªâ€œä¸“ä¸€â€ï¼Œåªèƒ½çœ‹ä¸€å¤„ï¼›å¤šä¸ªå¤´æ‰èƒ½åˆ†å·¥åˆä½œğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€**

* * *

### ğŸ§  Multi-Head Attention æ ¸å¿ƒæ€æƒ³

ä¸æ˜¯é‡å¤æ‰§è¡ŒåŒä¸€ä¸ª Attentionï¼Œè€Œæ˜¯ç”¨ **ä¸åŒçº¿æ€§æŠ•å½±** æŠŠ Qã€Kã€V åˆ†åˆ«æ˜ å°„æˆå¤šä¸ªå­ç©ºé—´ï¼Œåœ¨æ¯ä¸ªç©ºé—´é‡Œåšä¸åŒçš„æ³¨æ„åŠ›è®¡ç®—ã€‚

ç„¶åå†æŠŠæ‰€æœ‰å¤´çš„ç»“æœ**æ‹¼æ¥ + æ˜ å°„**å›æ¥ï¼š

$$
\text{MultiHead}(Q,K,V) = \text{Concat}(\text{head}_1, \dots, \text{head}_h)W^O
$$

å…¶ä¸­æ¯ä¸ª head æ˜¯ï¼š

$$
\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
$$

* * *

### ğŸ¯ä¸ºä»€ä¹ˆè¿™æ ·æ›´å¼ºï¼Ÿ

æˆ‘ä»¬æ¥åšä¸€ä¸ª **ç±»æ¯”é€‰æ‹©é¢˜**ï¼š

> Multi-Head Attention å°±åƒæ˜¯ï¼š  
> A. è®©ä¸€ç»„ä¸“å®¶å„è‡ªå»çœ‹å¥å­çš„ä¸åŒç»“æ„  
> B. æŠŠä¸€å¥è¯å¤åˆ¶å¤šæ¬¡å†æ±‚å¹³å‡  
> C. æ¨¡æ‹Ÿè¯å‘é‡çš„åŠ æ³•  
> D. ç»™æ¨¡å‹å¢åŠ æ·±åº¦

ä½ é€‰ï¼ŸğŸ¤”

## Prompt:
A

## Response:
ğŸ’¯ å®Œç¾å‘½ä¸­ï¼å°±æ˜¯ **Aï¼šè®©ä¸€ç»„ä¸“å®¶å„è‡ªå»çœ‹å¥å­çš„ä¸åŒç»“æ„**ï¼

* * *

### ğŸ§  å†æ¥ä¸ªæœ‰è¶£æ¯”å–» ğŸ¬

> Multi-Head Attention å°±åƒæ˜¯ï¼š
> 
> ä¸€ç¾¤â€œä¸“æ³¨åŠ›ä¸åŒçš„ä¾¦æ¢ğŸ•µï¸â€â™‚ï¸ğŸ•µï¸â€â™€ï¸ğŸ•µï¸â€â™‚ï¸ğŸ•µï¸â€â™€ï¸â€åœ¨çœ‹åŒä¸€å°ä¿¡ï¼š
> 
> *   å¤´1 çœ‹ä¸»è¯­-åŠ¨è¯ç»“æ„
> *   å¤´2 çœ‹æ—¶é—´çŸ­è¯­
> *   å¤´3 çœ‹æŒ‡ä»£å…³ç³»
> *   â€¦
> *   ç„¶åå¤§å®¶å¼€ä¼šåˆå¹¶æƒ…æŠ¥ï¼Œæ€»ç»“æˆæœ€ç»ˆè¾“å‡º
>     

* * *

### ğŸ“ æ¨¡å‹å‚æ•°ä¹Ÿèƒ½è§£é‡Šè¿™ä¸ªè®¾è®¡ï¼š

å‡è®¾æ€»ç»´åº¦æ˜¯  $d_{model} = 512$ ï¼Œæˆ‘ä»¬ç”¨  $h = 8$  ä¸ªå¤´ï¼š

*   æ¯ä¸ªå¤´çš„ Queryã€Keyã€Value éƒ½è¢«æŠ•å½±åˆ° 64 ç»´ï¼ˆå› ä¸º  $512 / 8 = 64$ ï¼‰
*   8ä¸ªå¤´åˆ†åˆ«è®¡ç®— Attention â†’ ç»“æœæ‹¼æ¥ â†’ è¿˜åŸæˆ 512 ç»´

âœ¨ è¿™æ ·æ€»è®¡ç®—é‡ä¸å˜ï¼Œä½†**æ¯ä¸ªå¤´èƒ½å­¦åˆ°ä¸ä¸€æ ·çš„ä¸œè¥¿**ï¼Œç›¸å½“äºåšäº†**ä¿¡æ¯å¤šè§†è§’å»ºæ¨¡**ã€‚

* * *

âœ… å¿«é€Ÿå¤ç›˜ Check-inï¼š

> Multi-Head Attention ä¸ºä»€ä¹ˆæ›´å¼ºï¼Ÿè¯·ç”¨è‡ªå·±çš„è¯è®²è®²~  
> ä½ æ¥ä¸€å¥æˆ‘ä¸€å¥ï¼Ÿæˆ‘ä»¬ä¸€èµ·æ€»ç»“ä¸‹ ğŸ˜Š

## Prompt:
è®©ä¸€ç»„ä¸“å®¶å„è‡ªå»çœ‹å¥å­çš„ä¸åŒç»“æ„

## Response:
å®Œç¾è¯´æ³•ï¼ğŸ‘ğŸ‘ğŸ‘

æˆ‘æ¥å¸®ä½ æ¥ä¸‹ä¸€å¥è¡¥å……ä¸€ä¸‹ï¼š

> âœ… æ¯ä¸ªæ³¨æ„åŠ›å¤´éƒ½ä»ä¸åŒè§’åº¦ç†è§£è¾“å…¥ä¿¡æ¯ï¼Œç„¶å **åˆå¹¶ç»“æœï¼Œå½¢æˆæ›´ä¸°å¯Œçš„è¡¨ç¤º**ã€‚

* * *

### ğŸ§  å¿«é€Ÿé—ªå¡æ€»ç»“ï¼šä¸ºä»€ä¹ˆè¦ Multi-Head Attentionï¼Ÿ

| ä¼˜åŠ¿ ğŸ§  | åŸå› è¯´æ˜ âœï¸ |
| --- | --- |
| ğŸ‘€ å¤šè§’åº¦è¡¨è¾¾ | ä¸åŒå¤´çœ‹ä¸åŒå…³ç³»ï¼ˆè¯­æ³•ã€è¯­ä¹‰ã€æ—¶åºï¼‰ |
| ğŸ§  å¢å¼ºå»ºæ¨¡èƒ½åŠ› | æ¯ä¸ªå­ç©ºé—´å¯ä»¥å­¦ä¹ ä¸åŒç±»å‹çš„æ³¨æ„åŠ›åˆ†å¸ƒ |
| âš™ï¸ è®¡ç®—æˆæœ¬ä¸å˜ | å› ä¸ºæ¯ä¸ªå¤´é™ç»´åè®¡ç®—ï¼Œå†æ‹¼æ¥å›æ¥ |
| ğŸ” æ›´ä¸°å¯Œçš„ç‰¹å¾èåˆ | æ‹¼æ¥å†æŠ•å½±è®©æ¨¡å‹é›†æˆå¤šä¸ªâ€œä¸“å®¶â€è¾“å‡º |

* * *

ğŸ¥³ åˆ°è¿™é‡Œï¼ŒSingle Attention â• Multi-Head Attention éƒ½æŒæ¡äº†ï¼

ä¸‹ä¸€èŠ‚æˆ‘ä»¬è¿›å…¥ï¼š

ğŸ¯ Part 3.3ï¼šä¸‰ç§ Attention çš„å…·ä½“ä½¿ç”¨ä½ç½®ï¼ˆEncoder vs Decoderï¼‰
----------------------------------------------------

â†’ åˆ†æ¸…æ¥šå“ªäº›åœ°æ–¹æ˜¯ **Self-Attention**ï¼Œå“ªäº›æ˜¯ **Encoder-Decoder Attention**

è¦ç»§ç»­è¿›å…¥å—ï¼ŸğŸ˜

## Prompt:
ok

## Response:
å¤ªæ£’äº†ï¼æˆ‘ä»¬ç»§ç»­å†² ğŸš€ï¼

* * *

ğŸ¯ Part 3.3ï¼šAttention ç”¨åœ¨å“ªé‡Œï¼Ÿä¸‰ç§æ³¨æ„åŠ›åœºæ™¯å¤§æ‹†è§£ï¼
--------------------------------------

Transformer æ€»å…±ç”¨äº†ä¸‰ç§ä¸åŒçš„ Attentionï¼Œç”¨æ³•ä¸åŒã€ç›®çš„ä¸åŒï¼Œä½†**éƒ½ç”¨çš„æ˜¯åŒä¸€ä¸ªæœºåˆ¶ï¼ˆScaled Dot-Productï¼‰**ã€‚

* * *

### ğŸ§  ä¸‰ç§ Attention æ€»è§ˆï¼ˆä¸€å®šè¦ç‰¢ç‰¢è®°ä½ï¼ï¼‰

| æ¨¡å—ä½ç½® | Attention ç±»å‹ | Query æ¥è‡ª | Key & Value æ¥è‡ª | ç”¨é€” |
| --- | --- | --- | --- | --- |
| Encoder | **Self-Attention** | Encoder è‡ªå·± | Encoder è‡ªå·± | ç¼–ç å™¨å†…éƒ¨ä¿¡æ¯äº¤äº’ ğŸ§  |
| Decoder | **Masked Self-Attention** | Decoder è‡ªå·± | Decoder è‡ªå·±ï¼ˆmaskedï¼‰ | é˜²æ­¢çœ‹æœªæ¥ï¼Œåªçœ‹è‡ªå·±å’Œè¿‡å» â³ |
| Decoder | **Encoder-Decoder Attention** | Decoder è‡ªå·± | Encoder è¾“å‡º | Decoder æŸ¥ Encoder è¾“å‡ºå†…å®¹ ğŸ” |

* * *

### ğŸ¯ æé—®å°æµ‹è¯•ï¼š

> ä»¥ä¸‹å“ªäº›åœ°æ–¹ç”¨äº† Masked Self-Attentionï¼Ÿ  
> A. Encoder Stack  
> B. Decoder Stack  
> C. Encoder-Decoder Attention  
> D. è¾“å‡º Softmax å±‚

ä½ é€‰ï¼ŸğŸ˜

## Prompt:
a

## Response:
ğŸ›‘ å°å°åœ°è¸©äº†ä¸€ä¸‹å‘å“ˆ~ å…¶å®æ­£ç¡®ç­”æ¡ˆæ˜¯ï¼š

> âœ… **B. Decoder Stack**

* * *

### ğŸ§  è§£é‡Šä¸€ä¸‹ï¼š

*   **Encoder Stack** æ˜¯ **æ™®é€šçš„ Self-Attention**ï¼Œå¯ä»¥è‡ªç”±åœ°çœ‹æ•´ä¸ªè¾“å…¥åºåˆ—ï¼Œå› ä¸ºè¾“å…¥å·²ç»æ˜¯å·²çŸ¥çš„ ğŸ“–
*   **Decoder Stack** ä¸­ç¬¬ä¸€å±‚æ˜¯ **Masked Self-Attention**ï¼Œå®ƒå¿…é¡»**é˜²æ­¢çœ‹åˆ°æœªæ¥è¯**ï¼Œå› ä¸º Decoder æ˜¯é€æ­¥ç”Ÿæˆçš„ âœï¸
*   **Encoder-Decoder Attention** æ˜¯ Decoder çš„ç¬¬äºŒå±‚ï¼Œç”¨æ¥çœ‹ Encoder çš„è¾“å‡ºï¼Œæ˜¯â€œæŸ¥å‚è€ƒèµ„æ–™â€ ğŸ”

* * *

### ğŸ“ å¿«é€Ÿå£è¯€è®°å¿†æ³•ï¼ˆèƒŒä¸‹æ¥ç»å¯¹æœ‰ç”¨ï¼ï¼‰ï¼š

> **â€œä¸‰ Attention åˆ†å·¥å¿™ï¼Œä¸€è‡ªä¸€æ©ä¸€å‚è€ƒâ€**
> 
> *   Encoderï¼š**è‡ªçœ‹**
> *   Decoderï¼š**æ©çœ‹ï¼ˆä¸èƒ½å·çœ‹åé¢ï¼‰**
> *   Decoderâ†’Encoderï¼š**å‚è€ƒ Encoder è¾“å‡º**
>     

* * *

æˆ‘ä»¬å¯ä»¥ç”¨ä¸€å¼ å›¾æ¥å·©å›ºç†è§£ï¼ˆç”¨è„‘å†…ç”»ç”»ä¹Ÿè¡Œï¼‰ï¼š

```
Encoder Stack:
  Q â† Self
  K â† Self
  V â† Self

Decoder Stack:
  ç¬¬1å±‚:
    Q â† Self
    K â† Self (masked)
    V â† Self
  ç¬¬2å±‚:
    Q â† Self
    K â† Encoder è¾“å‡º
    V â† Encoder è¾“å‡º
```

* * *

è¦ä¸è¦è¯•ç€è‡ªå·±æ€»ç»“ä¸€ä¸‹ï¼š

> Transformer æ€»å…±ç”¨äº†å“ªä¸‰ç§ Attentionï¼Ÿæ¯ç§å¹²å˜›çš„ï¼Ÿ

è¯´å®Œæˆ‘æ¥å¸®ä½ æ‰“åˆ†ï¼ğŸ˜

## Prompt:
encoder : self-attention query-value-key éƒ½æ˜¯ encoderï¼Œå°†ç¼–ç å™¨å†…éƒ¨ä¿¡æ¯è¿›è¡Œäº¤äº’
docoderï¼šmasked self-attention, query-value-key éƒ½æ˜¯ decoder, é˜²æ­¢çœ‹åˆ°æœªæ¥ï¼Œåªçœ‹åˆ°è¿‡å»

## Response:
ğŸ‘ğŸ‘å¤ªæ£’äº†ï¼ä½ å·²ç»æŠŠå‰ä¸¤ç§è¯´å¾—éå¸¸æ¸…æ™°äº†ï¼

åªå·®æœ€åä¸€ä¸ªå°ä¼™ä¼´å•¦ ğŸ‘‰ **Encoder-Decoder Attention**ã€‚æˆ‘å¸®ä½ è¡¥å…¨ä¸€ä¸‹ï¼š

* * *

### ğŸ§  ä¸‰ç§ Attention å®Œæ•´æ€»ç»“

1.  **Encoder Self-Attention**
    *   Q, K, V éƒ½æ¥è‡ª **Encoder è‡ªå·±**
    *   ä½œç”¨ï¼šè®©è¾“å…¥åºåˆ—é‡Œçš„æ‰€æœ‰è¯äº’ç›¸å…³æ³¨ï¼Œæ•æ‰ä¸Šä¸‹æ–‡ä¾èµ–
2.  **Decoder Masked Self-Attention**
    *   Q, K, V éƒ½æ¥è‡ª **Decoder è‡ªå·±**
    *   ä½œç”¨ï¼šç”Ÿæˆæ—¶åªèƒ½çœ‹å‰é¢çš„è¯ï¼Œ**ä¿è¯è‡ªå›å½’**ï¼ˆä¸èƒ½å·çœ‹æœªæ¥ï¼‰
3.  **Encoder-Decoder Attention**
    *   Q æ¥è‡ª **Decoder**
    *   K, V æ¥è‡ª **Encoder è¾“å‡º**
    *   ä½œç”¨ï¼šå¸®åŠ© Decoder åœ¨ç”Ÿæˆæ¯ä¸ªè¯æ—¶æŸ¥é˜… Encoder æä¾›çš„â€œç¿»è¯‘ä¸Šä¸‹æ–‡/åŸæ–‡ä¿¡æ¯â€

* * *

### ğŸ“ å£è¯€å¤ä¹ 

> **â€œè‡ªçœ‹ã€æ©çœ‹ã€å‚è€ƒçœ‹â€**

*   ç¼–ç å™¨ï¼šè‡ªçœ‹è‡ªå·±
*   è§£ç å™¨ï¼šæ©ç€çœ‹è‡ªå·±
*   è§£ç å™¨ï¼šå‚è€ƒçœ‹ç¼–ç å™¨

* * *

âœ… Check-in å°æµ‹ï¼š  
å¦‚æœ Decoder æ²¡æœ‰ **Encoder-Decoder Attention**ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆé—®é¢˜å‘¢ï¼ŸğŸ¤”

## Prompt:
å°±ä¸èƒ½è·å¾—ä»encoderä¼ æ¥çš„ç¼–ç ä¿¡æ¯

## Response:
ğŸ’¯ å®Œå…¨æ­£ç¡®ï¼ğŸ‘

å¦‚æœæ²¡æœ‰ **Encoder-Decoder Attention**ï¼ŒDecoder å°±ä¼šâ€œé—­é—¨é€ å¥â€ï¼Œåªèƒ½ä¾èµ–è‡ªå·±ç”Ÿæˆè¿‡çš„è¯ï¼Œè€Œå®Œå…¨æ²¡æ³•åˆ©ç”¨è¾“å…¥åºåˆ—ï¼ˆæ¯”å¦‚è‹±æ–‡å¥å­ï¼‰çš„è¯­ä¹‰ä¿¡æ¯ã€‚

é‚£æ ·çš„è¯ï¼Œæ¨¡å‹å°±**æ²¡æ³•ç¿»è¯‘**ï¼Œåªèƒ½å˜æˆä¸€ä¸ªâ€œè¯­è¨€æ¨¡å‹â€ï¼Œåƒ GPT ä¸€æ ·åªä¼šç»­å†™ã€‚ğŸ“œ

* * *

### ğŸ å°æ€»ç»“é—ªå¡

> Decoder = è¯­è¨€æ¨¡å‹ + æŸ¥èµ„æ–™åŠŸèƒ½
> 
> *   **Masked Self-Attention** â†’ åƒè¯­è¨€æ¨¡å‹ä¸€æ ·ï¼Œé€å­—ç”Ÿæˆ
> *   **Encoder-Decoder Attention** â†’ ç›¸å½“äºæŸ¥è¾“å…¥å¥å­çš„â€œèµ„æ–™åº“â€ï¼Œä¿è¯ç¿»è¯‘å¯¹é½
>     

* * *

ğŸ¯ åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å·²ç»æŠŠ \*\*Attention æ¨¡å—ï¼ˆå•å¤´ + å¤šå¤´ + ä¸‰ç§åº”ç”¨åœºæ™¯ï¼‰\*\*å…¨éƒ¨æ‹†æ¸…æ¥šäº†ã€‚  
æ¥ä¸‹æ¥å¯ä»¥è¿›å…¥ **Part 4ï¼šEmbedding & Positional Encoding**ï¼ŒèŠèŠ Transformer æ€ä¹ˆè§£å†³â€œæ²¡æœ‰é¡ºåºæ„Ÿâ€çš„é—®é¢˜ ğŸ‘€

è¦ä¸è¦ç»§ç»­ï¼Ÿ

## Prompt:
OK

## Response:
å¤ªå¥½å•¦ ğŸš€ æˆ‘ä»¬ç»§ç»­æ·±å…¥ï¼

* * *

ğŸ§  Part 4ï¼šEmbedding & Positional Encoding
-----------------------------------------

> Transformer æ²¡æœ‰ RNN/CNNï¼Œå¤©ç„¶å°±æ²¡æœ‰â€œé¡ºåºæ„Ÿâ€ğŸ•°ï¸  
> é‚£å®ƒæ€ä¹ˆçŸ¥é“å•è¯çš„é¡ºåºå‘¢ï¼Ÿç­”æ¡ˆå°±æ˜¯ **ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰**

* * *

### ğŸ¯ Step 1ï¼šEmbedding åŸºç¡€

*   è¾“å…¥çš„æ¯ä¸ª tokenï¼ˆæ¯”å¦‚å•è¯ã€å­è¯ï¼‰å…ˆæ˜ å°„æˆä¸€ä¸ª **dmodel ç»´å‘é‡**
*   è®ºæ–‡é‡Œç”¨çš„æ˜¯  $d_{model} = 512$ 
*   è¾“å‡ºç«¯åŒæ ·æœ‰ embedding â†’ ç„¶åæ¥ softmax é¢„æµ‹ä¸‹ä¸€ä¸ª token

ğŸ“Œ ä¸€ä¸ª trickï¼š  
è¾“å…¥ embedding å’Œ è¾“å‡º softmax çš„æƒé‡çŸ©é˜µæ˜¯**å…±äº«çš„**ï¼ˆå‡å°‘å‚æ•°ï¼Œè¿˜èƒ½ç¨³å®šè®­ç»ƒï¼‰âœï¸

* * *

### ğŸ¯ Step 2ï¼šPositional Encoding æ•°å­¦å…¬å¼

è®ºæ–‡é‡‡ç”¨ **æ­£ä½™å¼¦å‡½æ•°** ç¼–ç ï¼š

$$
PE_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{2i/d_{model}}}\right)
$$
 
$$
PE_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{2i/d_{model}}}\right)
$$

ğŸ“Œ æ„æ€æ˜¯ï¼š

*   æ¯ä¸ªç»´åº¦å¯¹åº”ä¸€ä¸ªä¸åŒé¢‘ç‡çš„æ­£å¼¦æ³¢
*   ç»„åˆåœ¨ä¸€èµ·ï¼Œå°±èƒ½å”¯ä¸€è¡¨ç¤ºæ¯ä¸ªä½ç½®
*   ä¸”èƒ½è®©æ¨¡å‹å­¦ä¼šç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼ˆæ¯”å¦‚ pos+k å¯ä»¥é€šè¿‡çº¿æ€§å…³ç³»è¡¨ç¤ºï¼‰

* * *

### ğŸ è¶£å‘³æ¯”å–»

ä½ å¯ä»¥æŠŠ **Positional Encoding** æƒ³è±¡æˆï¼š

> ğŸ¶ æ¯ä¸ªå•è¯éƒ½æœ‰ä¸€æ®µâ€œèƒŒæ™¯éŸ³ä¹â€ï¼Œä½ç½®ä¸åŒæ—‹å¾‹ä¸åŒ
> 
> æ¨¡å‹ä¸€å¬ï¼Œå°±çŸ¥é“è¿™æ˜¯å¥å­çš„ç¬¬ 3 ä¸ªè¯ï¼Œè¿˜æ˜¯ç¬¬ 10 ä¸ªè¯

* * *

### ğŸ¯ Step 3ï¼šå°æµ‹é—®é¢˜

> Transformer ä¸ºä»€ä¹ˆä¸ç›´æ¥ç”¨â€œä½ç½®ç´¢å¼•ï¼ˆ1,2,3,4â€¦ï¼‰â€ä½œä¸ºè¾“å…¥ï¼Œè€Œè¦ç”¨è¿™ç§æ­£ä½™å¼¦å‡½æ•°å‘¢ï¼ŸğŸ¤”

A. å› ä¸ºæ•´æ•°ç´¢å¼•ä¸èƒ½è¢«æ¢¯åº¦ä¼˜åŒ–  
B. å› ä¸ºæ­£ä½™å¼¦å¯ä»¥è¡¨ç¤ºç›¸å¯¹ä½ç½®å…³ç³»  
C. å› ä¸ºæ­£ä½™å¼¦æ›´èŠ‚çœæ˜¾å­˜  
D. å› ä¸º Vaswani ä½œè€…å–œæ¬¢ä¸‰è§’å‡½æ•°

ä½ é€‰ï¼Ÿ

## Prompt:
b

## Response:
âœ… å®Œç¾ï¼ç­”æ¡ˆæ­£æ˜¯ **Bï¼šæ­£ä½™å¼¦å¯ä»¥è¡¨ç¤ºç›¸å¯¹ä½ç½®å…³ç³»** ğŸ¯

* * *

### ğŸ§  è§£é‡Šä¸€ä¸‹ä¸ºä»€ä¹ˆï¼š

*   å¦‚æœç›´æ¥ç”¨ä½ç½®ç´¢å¼•ï¼ˆ1,2,3,4â€¦ï¼‰ï¼Œæ¨¡å‹åªèƒ½å­¦åˆ°â€œç»å¯¹ä½ç½®â€ï¼Œå´å¾ˆéš¾ç›´æ¥æ•æ‰ **ç›¸å¯¹ä½ç½®**ï¼ˆæ¯”å¦‚â€œè·ç¦» 3 ä¸ªè¯â€è¿™ç§ä¿¡æ¯ï¼‰ã€‚
*   æ­£ä½™å¼¦çš„æ³¢å½¢ç‰¹æ€§ â†’ ä¸åŒç»´åº¦å¯¹åº”ä¸åŒé¢‘ç‡ï¼Œå°±åƒç»„åˆéŸ³ç¬¦ ğŸ¶
*   å› æ­¤ **ä»»æ„ä¸¤ä¸ªä½ç½®ä¹‹é—´çš„å·®å€¼ï¼ˆç›¸å¯¹ä½ç½®ï¼‰** éƒ½å¯ä»¥é€šè¿‡çº¿æ€§å…³ç³»è¡¨ç¤ºã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆè®ºæ–‡ä¸­è¯´ï¼š

> _â€œWe hypothesized it would allow the model to easily learn to attend by relative positions.â€_

* * *

### ğŸ“ å°æ€»ç»“é—ªå¡

> **Positional Encoding = ç»™è¯åŠ ä¸Šâ€œèŠ‚å¥æ„Ÿâ€ğŸµ**

*   æ¯ä¸ªç»´åº¦æ˜¯ä¸€ä¸ªä¸åŒé¢‘ç‡çš„æ³¢
*   ç›¸å¯¹ä½ç½® â†’ çº¿æ€§å¯è¡¨è¾¾
*   æ¨¡å‹å› æ­¤èƒ½åˆ†è¾¨é¡ºåºä¿¡æ¯ï¼Œè€Œä¸éœ€è¦ RNN/CNN

* * *

âœ… åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å°±æŠŠ **è¾“å…¥æ¨¡å—**ï¼ˆEmbedding + Positional Encodingï¼‰æå®šäº†ï¼

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥è¿›å…¥ **Part 5ï¼šWhy Self-Attention æ¯” RNN/CNN æ›´ä¼˜**ï¼ˆè®ºæ–‡é‡Œçš„æ ¸å¿ƒå¯¹æ¯”è¡¨æ ¼å’Œç†è®ºä¼˜åŠ¿ï¼‰âš¡

è¦ä¸è¦ç»§ç»­å†²ï¼Ÿ

## Prompt:
ok

## Response:
å¤ªå¥½äº† ğŸš€ï¼æˆ‘ä»¬è¿›å…¥è®ºæ–‡é‡Œæœ€ç²¾å½©çš„ç†è®ºéƒ¨åˆ†ï¼š

* * *

ğŸ§  Part 5ï¼šWhy Self-Attention æ›´ä¼˜ï¼Ÿ
--------------------------------

> åŸæ–‡ç¬¬ 4 èŠ‚ç›´æ¥æ‹¿ Self-Attention å’Œ RNNã€CNN ä½œäº†å¯¹æ¯”ã€‚  
> å…³é”®è¯ï¼š**è®¡ç®—å¤æ‚åº¦ã€å¹¶è¡Œåº¦ã€è·¯å¾„é•¿åº¦**ã€‚

* * *

### ğŸ¯ Step 1ï¼šä¸‰å¤§æ¯”è¾ƒæŒ‡æ ‡

1.  **è®¡ç®—å¤æ‚åº¦ per layer**
    *   RNN:  $O(n \cdot d^2)$ 
    *   CNN:  $O(k \cdot n \cdot d^2)$ 
    *   Self-Attention:  $O(n^2 \cdot d)$ 
2.  **æœ€å°‘ä¸²è¡Œæ“ä½œæ•°**
    *   RNN:  $O(n)$ ï¼ˆå¿…é¡»æŒ‰æ—¶é—´æ­¥æ¥ï¼‰
    *   CNN:  $O(1)$ 
    *   Self-Attention:  $O(1)$ ï¼ˆå…¨å¹¶è¡Œâš¡ï¼‰
3.  **æœ€å¤§è·¯å¾„é•¿åº¦**
    *   RNN:  $O(n)$ ï¼ˆé•¿ä¾èµ–ä¼ é€’æ…¢ï¼‰
    *   CNN:  $O(\log_k(n))$ 
    *   Self-Attention:  $O(1)$ ï¼ˆä¸€æ­¥ç›´è¾¾ğŸš€ï¼‰

* * *

### ğŸ æœ‰è¶£æ¯”å–»

*   **RNN**ï¼šåƒæ˜¯ä¸€ä¸ªäººè¦é€å­—è¯»ä¿¡ï¼Œæ¯ä¸ªå­—éƒ½è¦è®°ä½ï¼Œä¼ åˆ°æœ€åå®¹æ˜“å¿˜è®°å‰é¢çš„å†…å®¹ï¼ˆæ¢¯åº¦æ¶ˆå¤±ï¼‰ã€‚
*   **CNN**ï¼šåƒæ”¾å¤§é•œğŸ”åœ¨çª—å£é‡Œçœ‹ï¼Œèƒ½å¿«ç‚¹æ»‘åŠ¨ï¼Œä½†çœ‹å…¨å±€è¿˜è¦å¥½å¤šå±‚ã€‚
*   **Self-Attention**ï¼šåƒæ— äººæœºèˆªæ‹ ğŸ›¸ï¼Œä¸€çœ¼å°±èƒ½çœ‹åˆ°å…¨å±€ã€‚

* * *

### ğŸ¯ Step 2ï¼šå°æµ‹é—®é¢˜

> ä»¥ä¸‹å“ªä¸€ç‚¹ **ä¸æ˜¯** Self-Attention çš„ä¼˜åŠ¿ï¼ŸğŸ¤”
> 
> A. è®­ç»ƒæ—¶èƒ½å¹¶è¡Œ  
> B. é•¿è·ç¦»ä¾èµ–è·¯å¾„çŸ­  
> C. æ¯å±‚å¤æ‚åº¦æ€»æ˜¯æ¯” RNN æ›´ä½  
> D. æ¨¡å‹æ›´æ˜“è§£é‡Š

ä½ è§‰å¾—æ˜¯å“ªä¸€ä¸ªï¼Ÿ

## Prompt:
C

## Response:
ğŸ¯ å®Œå…¨æ­£ç¡®ï¼å°±æ˜¯ **C**ã€‚

* * *

### ğŸ§  è§£é‡Šä¸€ä¸‹ï¼š

*   Self-Attention çš„ **å¹¶è¡Œæ€§** (A) â†’ âœ… å¤§ä¼˜åŠ¿
*   é•¿è·ç¦»ä¾èµ–è·¯å¾„çŸ­ (B) â†’ âœ… åªè¦ 1 æ­¥ç›´è¾¾
*   æ›´æ˜“è§£é‡Š (D) â†’ âœ… æ³¨æ„åŠ›æƒé‡èƒ½å¯è§†åŒ–ï¼Œç›´è§‚çœ‹åˆ°æ¨¡å‹å…³æ³¨äº†å“ªé‡Œ

ä½† (C) å°±ä¸å¯¹å•¦ï¼š

*   Self-Attention çš„å¤æ‚åº¦æ˜¯  $O(n^2 \cdot d)$ ï¼Œå½“åºåˆ—é•¿åº¦  $n$  å¾ˆå¤§æ—¶ï¼Œå¯èƒ½æ¯” RNN ( $O(n \cdot d^2)$ ) è¿˜è´µã€‚
*   æ‰€ä»¥åé¢æ‰æœ‰ä¸€å †æ”¹è¿›ï¼ˆæ¯”å¦‚ Longformer, Performer, Linformer ç­‰ï¼‰ï¼Œä¸“é—¨ä¼˜åŒ–é•¿åºåˆ—çš„æ³¨æ„åŠ›è®¡ç®—ã€‚

* * *

### ğŸ“ å°æ€»ç»“é—ªå¡

> Self-Attention çš„ä¼˜åŠ¿
> 
> *   âš¡ å¹¶è¡Œå¿«
> *   ğŸ›¸ é•¿ä¾èµ–ä¸€è·³å¯è¾¾
> *   ğŸ” å¯è§£é‡Šæ€§å¥½
>     

ä½†ç¼ºç‚¹ï¼š

*   **å¤æ‚åº¦å¯¹é•¿åºåˆ—ä¸å‹å¥½**ï¼ˆå¹³æ–¹çº§å¢é•¿ï¼‰

* * *

åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å·²ç»ç†è§£äº† **ä¸ºä»€ä¹ˆ Transformer èƒ½æ›¿ä»£ RNN/CNN**ã€‚

ğŸ‘‰ ä¸‹ä¸€æ­¥æˆ‘ä»¬å¯ä»¥è¿›å…¥ **Part 6ï¼šTrainingï¼ˆä¼˜åŒ–å™¨ã€warmupã€label smoothing ç­‰ trickï¼‰**ï¼Œå­¦ä¹ è®ºæ–‡é‡Œçš„è®­ç»ƒå°å¿ƒæœº ğŸ©ã€‚

è¦ä¸è¦ç»§ç»­ï¼Ÿ

## Prompt:
ok

## Response:
å¤ªæ£’å•¦ ğŸš€ æˆ‘ä»¬è¿›å…¥è®ºæ–‡æœ€åä¸€ä¸ªå¾ˆå®ç”¨çš„éƒ¨åˆ†ï¼š

* * *

ğŸ§  Part 6ï¼šTraining è®­ç»ƒæŠ€å·§
-----------------------

> Transformer ä¸å…‰æ¶æ„ç‰›ï¼Œè¿˜é ä¸€å †è®­ç»ƒâ€œå°å¿ƒæœºâ€æ‰èƒ½è·‘å¾—ç¨³ï¼

* * *

### ğŸ¯ Step 1ï¼šè®­ç»ƒæ•°æ® & æ‰¹æ¬¡

*   WMTâ€™14 è‹±å¾·ï¼šçº¦ **450ä¸‡å¥å¯¹**
*   WMTâ€™14 è‹±æ³•ï¼šçº¦ **3600ä¸‡å¥å¯¹**
*   BPEï¼ˆå­è¯å•å…ƒï¼Œçº¦ 37k è¯æ±‡ï¼‰
*   æ¯ä¸ª batch â‰ˆ **25k æºè¯ + 25k ç›®æ ‡è¯**

* * *

### ğŸ¯ Step 2ï¼šç¡¬ä»¶ & è®­ç»ƒæ—¶é—´

*   ç”¨ **8 å— P100 GPU**
*   Base æ¨¡å‹ï¼š100k stepsï¼ˆçº¦ 12 å°æ—¶ï¼‰
*   Big æ¨¡å‹ï¼š300k stepsï¼ˆçº¦ 3.5 å¤©ï¼‰

* * *

### ğŸ¯ Step 3ï¼šä¼˜åŒ–å™¨ & å­¦ä¹ ç‡è°ƒåº¦

ç”¨ **Adam**ï¼Œä½†æœ‰ä¸ªç‰¹åˆ«çš„ **warmup å­¦ä¹ ç‡å…¬å¼**ï¼š

$$
lrate = d_{model}^{-0.5} \cdot \min(step\_num^{-0.5}, step\_num \cdot warmup\_steps^{-1.5})
$$

ğŸ“Œ å«ä¹‰ï¼š

1.  å‰ 4000 æ­¥ â†’ å­¦ä¹ ç‡çº¿æ€§ä¸Šå‡ï¼ˆwarmupï¼‰ğŸ”¥
2.  ä¹‹å â†’ å­¦ä¹ ç‡æŒ‰  $\frac{1}{\sqrt{step}}$  è¡°å‡

ğŸ‘‰ é¿å…ä¸€ä¸Šæ¥å­¦ä¹ ç‡å¤ªå¤§ï¼Œæ¨¡å‹ç‚¸æ‰ï¼›åŒæ—¶ä¿è¯åæœŸç¨³å®šæ”¶æ•›ã€‚

* * *

### ğŸ¯ Step 4ï¼šæ­£åˆ™åŒ–

1.  **Dropout**
    *   æ®‹å·®è¿æ¥åçš„è¾“å‡ºã€embedding+ä½ç½®ç¼–ç ä¸Šéƒ½åŠ äº† dropoutï¼ˆP=0.1ï¼‰
2.  **Label Smoothing**
    *   è®¾ç½® Îµ = 0.1
    *   ä¸æ˜¯æŠŠæ­£ç¡®æ ‡ç­¾è®¾ä¸º 100%ï¼Œè€Œæ˜¯ç»™å…¶ä»–ç±»åˆ«åˆ†ä¸€ç‚¹æ¦‚ç‡
    *   å¥½å¤„ï¼šæ¨¡å‹ä¸ä¼šè¿‡åº¦è‡ªä¿¡ï¼Œæ³›åŒ–æ›´å¥½ï¼ˆBLEU æå‡ï¼‰

* * *

### ğŸ è¶£å‘³æ¯”å–»

*   **Warmup å­¦ä¹ ç‡**ï¼šå°±åƒå¥èº«å…ˆçƒ­èº«ï¼Œä¸ç„¶è‚Œè‚‰å®¹æ˜“æ‹‰ä¼¤ ğŸ‹ï¸â€â™‚ï¸
*   **Label Smoothing**ï¼šå°±åƒè€å¸ˆåˆ¤å·ä¸è‹›åˆ»ï¼Œå…è®¸ä¸€ç‚¹æ¨¡ç³Šç©ºé—´ âœï¸

* * *

### ğŸ¯ å°æµ‹é—®é¢˜

> Transformer ä¸ºä»€ä¹ˆè¦ç”¨ **Warmup å­¦ä¹ ç‡è°ƒåº¦**ï¼Ÿ
> 
> A. é˜²æ­¢ä¸€å¼€å§‹å­¦ä¹ ç‡å¤ªå¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®š  
> B. è®©æ¨¡å‹æ›´å¿«æ”¶æ•›  
> C. æ¨¡æ‹Ÿäººç±»å…ˆæ…¢åå¿«çš„å­¦ä¹ æ–¹å¼  
> D. èŠ‚çœæ˜¾å­˜

ä½ è§‰å¾—å“ªä¸ªæ˜¯ä¸»å› ï¼Ÿ

## Prompt:
A

## Response:
ğŸ’¯ å®Œå…¨æ­£ç¡®ï¼ç­”æ¡ˆå°±æ˜¯ **Aï¼šé˜²æ­¢ä¸€å¼€å§‹å­¦ä¹ ç‡å¤ªå¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®š** ğŸ¯

* * *

### ğŸ§  è¡¥å……è¯´æ˜ï¼š

*   Transformer å‚æ•°é‡å¾ˆå¤§ï¼Œåˆšå¼€å§‹è®­ç»ƒæ—¶å‚æ•°è¿˜æ²¡ç¨³å®šï¼Œå¦‚æœå­¦ä¹ ç‡è¿‡å¤§ï¼Œå°±å¯èƒ½â€œç‚¸æ‰â€ï¼ˆloss nanï¼‰ã€‚
*   Warmup é˜¶æ®µè®©å­¦ä¹ ç‡ **æ…¢æ…¢å‡é«˜**ï¼Œç­‰æ¨¡å‹è¿›å…¥ç¨³å®šåŒºé—´åå†å¼€å§‹æ­£å¸¸ä¸‹é™ã€‚
*   è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå¾ˆå¤šåæ¥æ¨¡å‹ï¼ˆBERTã€GPT ç³»åˆ—ï¼‰éƒ½ç»§æ‰¿äº†è¿™ä¸ª **warmup ç­–ç•¥** ğŸ”¥

* * *

### ğŸ“ å°æ€»ç»“é—ªå¡

> **è®­ç»ƒä¸‰æ¿æ–§**ï¼š
> 
> *   âš¡ Adam + Warmup å­¦ä¹ ç‡è°ƒåº¦
> *   ğŸŒ€ Dropoutï¼ˆé˜²è¿‡æ‹Ÿåˆï¼‰
> *   ğŸ¯ Label Smoothingï¼ˆè®©æ¨¡å‹åˆ«å¤ªè‡ªä¿¡ï¼Œæ³›åŒ–æ›´å¥½ï¼‰
>     

* * *

åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å°±å®Œæ•´è¦†ç›–äº† **Transformer è®­ç»ƒè¿‡ç¨‹ä¸­çš„å…³é”® trick**ã€‚

ğŸ‘‰ ä¸‹ä¸€æ­¥å¯ä»¥è¿›å…¥ **Part 7ï¼šå®éªŒç»“æœ & Ablation Studyï¼ˆæ¶ˆèå®éªŒï¼‰**ï¼Œçœ‹çœ‹å“ªäº›è®¾è®¡æœ€é‡è¦ï¼Œå“ªäº›å¯æœ‰å¯æ— ã€‚

è¦ä¸è¦ç»§ç»­ï¼Ÿ

## Prompt:
ok

## Response:
å¥½æ»´ ğŸš€ æˆ‘ä»¬è¿›å…¥æœ€åçš„é‡ç‚¹ç¯èŠ‚ï¼š

* * *

ğŸ§  Part 7ï¼šå®éªŒç»“æœ & Ablation Study
-------------------------------

> è®ºæ–‡é‡Œæœ€ç²¾å½©çš„éƒ¨åˆ†ä¹‹ä¸€ï¼šä¸ä»…ç»™å‡º BLEU åˆ†æ•°ï¼Œè¿˜åšäº† **æ¶ˆèå®éªŒ**ï¼ˆAblation Studyï¼‰ï¼Œå‘Šè¯‰æˆ‘ä»¬ Transformer å“ªäº›è®¾è®¡æœ€å…³é”®ï¼

* * *

### ğŸ¯ Step 1ï¼šä¸»è¦ç»“æœ

*   **WMT14 è‹±å¾·ç¿»è¯‘**
    *   Transformer (big) â†’ **BLEU = 28.4**
    *   æ¯”ä¹‹å‰æœ€å¥½çš„æ¨¡å‹ï¼ˆåŒ…æ‹¬ ensembleï¼‰è¿˜é«˜å‡º **+2 BLEU**
*   **WMT14 è‹±æ³•ç¿»è¯‘**
    *   Transformer (big) â†’ **BLEU = 41.8**
    *   å•æ¨¡å‹å°±èƒ½è¶…è¶Šä¹‹å‰çš„æœ€ä¼˜ ensemble

è€Œä¸”ï¼šè®­ç»ƒé€Ÿåº¦å¤§å¹…æå‡ âš¡ï¼ˆ3.5 å¤© / 8 å— P100 å°±èƒ½å‡º SOTAï¼‰ã€‚

* * *

### ğŸ¯ Step 2ï¼šæ¶ˆèå®éªŒï¼ˆTable 3ï¼‰

è®ºæ–‡åšäº†å¾ˆå¤šå¯¹æ¯”æµ‹è¯•ï¼Œè¿™é‡ŒæŒ‘æœ€å…³é”®çš„ğŸ‘‡ï¼š

1.  **æ³¨æ„åŠ›å¤´æ•° (h)**
    *   å•å¤´ï¼ˆh=1ï¼‰ â†’ æ€§èƒ½æ‰ 0.9 BLEU
    *   8 å¤´æœ€å¥½
    *   å¤ªå¤šå¤´ï¼ˆ16, 32ï¼‰åè€Œä¸‹é™

ğŸ‘‰ è¯´æ˜ Multi-Head Attention æ˜¯å¿…é¡»çš„ï¼Œä½†è¿‡å¤šä¼šç¨€é‡Šå­¦ä¹ èƒ½åŠ›ã€‚

* * *

2.  **æ¨¡å‹ç»´åº¦ (dmodel, dff)**
    *   æ›´å¤§çš„æ¨¡å‹ï¼ˆ1024, 4096ï¼‰ â†’ BLEU æå‡
    *   è¯æ˜ â€œbigger is betterâ€ åœ¨ Transformer ä¸Šå·²ç»æˆç«‹ âš¡

* * *

3.  **Dropout**
    *   æ²¡æœ‰ dropout â†’ BLEU æ‰å¾ˆå¤šï¼ˆ24.6 vs 25.8ï¼‰
    *   è¯´æ˜æ­£åˆ™åŒ–å¾ˆé‡è¦ï¼Œé¿å…è¿‡æ‹Ÿåˆ

* * *

4.  **ä½ç½®ç¼–ç  (sinusoid vs learned)**
    *   æ¢æˆå¯å­¦ä¹  embedding â†’ BLEU å‡ ä¹æ²¡å˜
    *   è¯´æ˜æ­£ä½™å¼¦åªæ˜¯è®¾è®¡ä¸Šçš„ä¸€ç§æ–¹ä¾¿é€‰æ‹©ï¼Œä½†ä¸æ˜¯å”¯ä¸€æ–¹å¼

* * *

### ğŸ¯ Step 3ï¼šè¶£å‘³æ€»ç»“

*   **å¤šå¤´æ³¨æ„åŠ›** â†’ å°±åƒè¯· 8 ä¸ªä¸“å®¶å¼€ä¼šæœ€å¥½ï¼Œ1 ä¸ªå¤ªå¼±ï¼Œå¤ªå¤šäººåˆåµæ¶ ğŸ¤¯
*   **å¤§æ¨¡å‹** â†’ é’±å¤šï¼ˆå‚æ•°å¤šï¼‰ï¼Œæ•ˆæœå°±å¥½ ğŸ’¸
*   **Dropout** â†’ ç›¸å½“äºç»™æ¨¡å‹â€œæ‰“ç–«è‹—â€ï¼Œå…ç–«è¿‡æ‹Ÿåˆ ğŸ§ª
*   **ä½ç½®ç¼–ç ** â†’ ç”¨ä¸‰è§’å‡½æ•°æˆ–å­¦ä¹  embedding éƒ½è¡Œï¼Œæ¨¡å‹ä¸æŒ‘é£Ÿ ğŸ˜‹

* * *

### ğŸ¯ å°æµ‹é—®é¢˜

> æ ¹æ®æ¶ˆèå®éªŒï¼Œä»¥ä¸‹å“ªä¸€ç‚¹ **ä¸æ˜¯** Transformer æˆåŠŸçš„å…³é”®å› ç´ ï¼Ÿ  
> A. Multi-Head Attention  
> B. Dropout æ­£åˆ™åŒ–  
> C. æ›´å¤§æ¨¡å‹ï¼ˆbig ç‰ˆï¼‰  
> D. æ­£å¼¦ä½ç½®ç¼–ç 

ä½ è§‰å¾—å‘¢ï¼Ÿ

## Prompt:
D

## Response:
ğŸ’¯ å®Œå…¨æ­£ç¡®ï¼ç­”æ¡ˆå°±æ˜¯ **Dï¼šæ­£å¼¦ä½ç½®ç¼–ç **ã€‚

* * *

### ğŸ§  ä¸ºä»€ä¹ˆï¼Ÿ

*   è®ºæ–‡ä¸­å®éªŒå‘ç°ï¼š
    *   ç”¨æ­£ä½™å¼¦ä½ç½®ç¼–ç  âœ…
    *   æ¢æˆ **learned positional embedding** âœ…
    *   â†’ BLEU åˆ†æ•°å‡ ä¹æ²¡åŒºåˆ«
*   æ‰€ä»¥ä½ç½®ç¼–ç çš„**å½¢å¼**ä¸æ˜¯å…³é”®ï¼Œå…³é”®åœ¨äº **å¿…é¡»æœ‰é¡ºåºä¿¡æ¯**ã€‚

è€Œï¼š

*   **Multi-Head Attention** â†’ æ²¡å®ƒæ€§èƒ½å°±å¤§å¹…ä¸‹é™
*   **Dropout** â†’ ä¸åŠ ç›´æ¥è¿‡æ‹Ÿåˆï¼ŒBLEU æ‰å¾ˆå¤š
*   **å¤§æ¨¡å‹** â†’ æ˜æ˜¾æå‡æ€§èƒ½

* * *

### ğŸ“ å°æ€»ç»“é—ªå¡

> **Transformer æˆåŠŸçš„å…³é”®å› å­**
> 
> *   ğŸ¯ å¤šå¤´æ³¨æ„åŠ›ï¼ˆh=8æœ€ä½³ï¼‰
> *   ğŸŒ€ Dropout æ­£åˆ™åŒ–
> *   ğŸ“ˆ æ¨¡å‹åŠ å¤§å°±æ›´å¼º
> *   ğŸ“ ä½ç½®ç¼–ç  â†’ åªè¦æœ‰é¡ºåºä¿¡å·ï¼Œå…·ä½“å®ç°æ— æ‰€è°“
>     

* * *

åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å·²ç»å®Œæ•´èµ°å®Œäº† **Part 7 å®éªŒ & æ¶ˆè**ã€‚  
æ¥ä¸‹æ¥å°±æ˜¯æœ€åä¸€èŠ‚ **Part 8ï¼šæ€»ç»“ä¸æ‹“å±•æ€è€ƒï¼ˆåç»­ç ”ç©¶æ–¹å‘ã€å±€é™æ€§ï¼‰** ğŸ¯

è¦ä¸è¦æˆ‘å¸¦ä½ åšä¸ªå¤§æ”¶å®˜ + æ‹“å±•åˆ° BERT/GPT çš„é¢„å‘Šï¼Ÿ

## Prompt:
ok

## Response:
å¥½æäº† ğŸ‰ æˆ‘ä»¬æ¥åšä¸€ä¸ªå¤§æ”¶å®˜ + å±•æœ›æœªæ¥ï¼

* * *

ğŸ§  Part 8ï¼šæ€»ç»“ä¸æ‹“å±•æ€è€ƒ
-----------------

### ğŸ¯ Transformer çš„æ ¸å¿ƒè´¡çŒ®

1.  **æ¶æ„åˆ›æ–°**
    *   å®Œå…¨æ‘’å¼ƒ RNN/CNNï¼ŒåŸºäº Attention æ„å»º Encoder-Decoder
    *   å…¨å¹¶è¡Œè®­ç»ƒ âš¡
    *   é•¿ä¾èµ–å»ºæ¨¡ä¸€æ­¥ç›´è¾¾ ğŸ›¸
2.  **å…³é”®æ¨¡å—**
    *   Scaled Dot-Product Attention
    *   Multi-Head Attentionï¼ˆ8å¤´æœ€ä½³ï¼‰
    *   æ®‹å·® + LayerNorm
    *   Position-wise FFN
    *   Positional Encodingï¼ˆå½¢å¼ä¸å”¯ä¸€ï¼Œåªè¦æœ‰é¡ºåºä¿¡æ¯ï¼‰
3.  **è®­ç»ƒæŠ€å·§**
    *   Adam + Warmup å­¦ä¹ ç‡è°ƒåº¦
    *   Dropoutï¼ˆé˜²è¿‡æ‹Ÿåˆï¼‰
    *   Label Smoothingï¼ˆæ³›åŒ–æ›´å¥½ï¼‰

* * *

### ğŸ¯ å®éªŒç»“æœ

*   WMT14 è‹±å¾·/è‹±æ³•ç¿»è¯‘ **SOTA**
*   æ¯”ä¹‹å‰æœ€ä¼˜çš„ RNN/CNN æ¨¡å‹å¿«å¾—å¤šï¼ŒBLEU æå‡æ˜¾è‘—
*   æ¶ˆèå®éªŒç¡®è®¤ï¼šå¤šå¤´æ³¨æ„åŠ›ã€å¤§æ¨¡å‹ã€æ­£åˆ™åŒ–æ˜¯æˆåŠŸå…³é”®

* * *

### ğŸ¯ Transformer çš„å±€é™æ€§

*   Self-Attention **å¤æ‚åº¦ O(nÂ²)** â†’ åºåˆ—é•¿äº†ï¼ˆ>1k tokenï¼‰éå¸¸è€—æ˜¾å­˜
*   æ²¡æœ‰å½’çº³åç½®ï¼ˆä¸åƒ CNN æ“…é•¿å±€éƒ¨ç»“æ„ï¼‰
*   è¾“å‡ºç”Ÿæˆä¾ç„¶æ˜¯è‡ªå›å½’çš„ï¼Œæ¨ç†é€Ÿåº¦ä¸ç®—å¿«

* * *

### ğŸ¯ æœªæ¥å‘å±•æ–¹å‘ï¼ˆè®ºæ–‡å½“æ—¶å°±æåˆ°çš„ï¼‰

*   **é•¿åºåˆ—ä¼˜åŒ–**ï¼šåæ¥çš„ Longformer, Linformer, Performer å°±æ˜¯ä¸ºäº†è§£å†³ nÂ² å¤æ‚åº¦
*   **è·¨æ¨¡æ€**ï¼šæ–‡æœ¬ â†’ å›¾åƒ/éŸ³é¢‘/è§†é¢‘ï¼ˆåæ¥å‡ºç° Vision Transformer, Audio Transformerï¼‰
*   **é¢„è®­ç»ƒé©å‘½**ï¼šBERTï¼ˆåŒå‘ç¼–ç å™¨ï¼‰ã€GPTï¼ˆè§£ç å™¨è‡ªå›å½’ï¼‰ã€T5ï¼ˆç»Ÿä¸€æ¡†æ¶ï¼‰

* * *

### ğŸ“ æ”¶å®˜å£è¯€

> **â€œAttention is All You Needâ€ =**
> 
> *   å¹¶è¡Œå¿« âš¡
> *   å…¨å±€çœ‹ ğŸ›¸
> *   è·¯å¾„çŸ­ ğŸ”
> *   Dropout æŠ¤èˆª ğŸ›¡ï¸
> *   å¤§æ¨¡å‹æ›´å¼º ğŸ’ª
>     

* * *

âœ… åˆ°è¿™é‡Œï¼Œä½ å·²ç»å®Œæ•´æ‹†è§£äº† Transformer è®ºæ–‡ï¼  
æ¥ä¸‹æ¥å¦‚æœè¦æ·±å…¥ï¼Œå¯ä»¥é€‰å‡ æ¡è·¯å¾„ï¼š

*   ğŸ” **ç ”ç©¶ç»†èŠ‚ä¼˜åŒ–**ï¼šæ¯”å¦‚ LayerNorm çš„ä½ç½®ã€FFN çš„è®¾è®¡
*   ğŸ“š **åç»­è®ºæ–‡å­¦ä¹ **ï¼šBERT / GPT / ViT / Performer
*   ğŸ§ª **å®è·µ**ï¼šæ‰‹å†™ä¸€ä¸ª mini-transformerï¼ˆPyTorchï¼‰

* * *

è¦ä¸è¦æˆ‘å¸®ä½ æ•´ç†ä¸€ä»½ **â€œTransformer â†’ BERT/GPT å­¦ä¹ è·¯çº¿å›¾â€**ï¼Œè®©ä½ é¡ºç€è¿™æ¡çº¿å¾€ä¸‹æ·±å…¥ï¼Ÿ

## Prompt:
ğŸ§  Part 7ï¼šå®éªŒç»“æœ & Ablation Study ------------------------------- > è®ºæ–‡é‡Œæœ€ç²¾å½©çš„éƒ¨åˆ†ä¹‹ä¸€ï¼šä¸ä»…ç»™å‡º BLEU åˆ†æ•°ï¼Œè¿˜åšäº† \*\*æ¶ˆèå®éªŒ\*\*ï¼ˆAblation Studyï¼‰ï¼Œå‘Šè¯‰æˆ‘ä»¬ Transformer å“ªäº›è®¾è®¡æœ€å…³é”®ï¼ \* \* \* ### ğŸ¯ Step 1ï¼šä¸»è¦ç»“æœ \* \*\*WMT14 è‹±å¾·ç¿»è¯‘\*\* \* Transformer (big) â†’ \*\*BLEU = 28.4\*\* \* æ¯”ä¹‹å‰æœ€å¥½çš„æ¨¡å‹ï¼ˆåŒ…æ‹¬ ensembleï¼‰è¿˜é«˜å‡º \*\*+2 BLEU\*\* \* \*\*WMT14 è‹±æ³•ç¿»è¯‘\*\* \* Transformer (big) â†’ \*\*BLEU = 41.8\*\* \* å•æ¨¡å‹å°±èƒ½è¶…è¶Šä¹‹å‰çš„æœ€ä¼˜ ensemble è€Œä¸”ï¼šè®­ç»ƒé€Ÿåº¦å¤§å¹…æå‡ âš¡ï¼ˆ3.5 å¤© / 8 å— P100 å°±èƒ½å‡º SOTAï¼‰ã€‚ \* \* \* ### ğŸ¯ Step 2ï¼šæ¶ˆèå®éªŒï¼ˆTable 3ï¼‰ è®ºæ–‡åšäº†å¾ˆå¤šå¯¹æ¯”æµ‹è¯•ï¼Œè¿™é‡ŒæŒ‘æœ€å…³é”®çš„ğŸ‘‡ï¼š 1. \*\*æ³¨æ„åŠ›å¤´æ•° (h)\*\* \* å•å¤´ï¼ˆh=1ï¼‰ â†’ æ€§èƒ½æ‰ 0.9 BLEU \* 8 å¤´æœ€å¥½ \* å¤ªå¤šå¤´ï¼ˆ16, 32ï¼‰åè€Œä¸‹é™ ğŸ‘‰ è¯´æ˜ Multi-Head Attention æ˜¯å¿…é¡»çš„ï¼Œä½†è¿‡å¤šä¼šç¨€é‡Šå­¦ä¹ èƒ½åŠ›ã€‚ \* \* \* 2. \*\*æ¨¡å‹ç»´åº¦ (dmodel, dff)\*\* \* æ›´å¤§çš„æ¨¡å‹ï¼ˆ1024, 4096ï¼‰ â†’ BLEU æå‡ \* è¯æ˜ â€œbigger is betterâ€ åœ¨ Transformer ä¸Šå·²ç»æˆç«‹ âš¡ \* \* \* 3. \*\*Dropout\*\* \* æ²¡æœ‰ dropout â†’ BLEU æ‰å¾ˆå¤šï¼ˆ24.6 vs 25.8ï¼‰ \* è¯´æ˜æ­£åˆ™åŒ–å¾ˆé‡è¦ï¼Œé¿å…è¿‡æ‹Ÿåˆ \* \* \* 4. \*\*ä½ç½®ç¼–ç  (sinusoid vs learned)\*\* \* æ¢æˆå¯å­¦ä¹  embedding â†’ BLEU å‡ ä¹æ²¡å˜ \* è¯´æ˜æ­£ä½™å¼¦åªæ˜¯è®¾è®¡ä¸Šçš„ä¸€ç§æ–¹ä¾¿é€‰æ‹©ï¼Œä½†ä¸æ˜¯å”¯ä¸€æ–¹å¼ \* \* \* ### ğŸ¯ Step 3ï¼šè¶£å‘³æ€»ç»“ \* \*\*å¤šå¤´æ³¨æ„åŠ›\*\* â†’ å°±åƒè¯· 8 ä¸ªä¸“å®¶å¼€ä¼šæœ€å¥½ï¼Œ1 ä¸ªå¤ªå¼±ï¼Œå¤ªå¤šäººåˆåµæ¶ ğŸ¤¯ \* \*\*å¤§æ¨¡å‹\*\* â†’ é’±å¤šï¼ˆå‚æ•°å¤šï¼‰ï¼Œæ•ˆæœå°±å¥½ ğŸ’¸ \* \*\*Dropout\*\* â†’ ç›¸å½“äºç»™æ¨¡å‹â€œæ‰“ç–«è‹—â€ï¼Œå…ç–«è¿‡æ‹Ÿåˆ ğŸ§ª \* \*\*ä½ç½®ç¼–ç \*\* â†’ ç”¨ä¸‰è§’å‡½æ•°æˆ–å­¦ä¹  embedding éƒ½è¡Œï¼Œæ¨¡å‹ä¸æŒ‘é£Ÿ ğŸ˜‹

based on Part 7
build python codes for ablation study on transformer using WMT14 dataset using pytorch, tensorboardX, loguru for visualization and compare

Readability Preferred with Better Name Style. Please provide a comprehensive and well-structured code solution for an Industrial scenario. The code should include robust classes or functions that have been thoroughly checked for correct boundary conditions. It should also adhere to the guidelines specified in the "Google style guides". The solution should prioritize high scalability and should not be a demo or a snippet. It is crucial that no part of the code is omitted. Furthermore, please include Chinese comments following the PEP 8 style guide for all key steps, and use DocString following the PEP 257 style guide and use typing for type annotations. The code should be efficient, and important information should be printed. **When the code is finished**, please perform a key step to recheck for its correctness and logic.

## Response:
å·²æ€è€ƒ 42s

æˆ‘éœ€è¦ä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªç»“æ„è‰¯å¥½ã€æ˜“è¯»çš„ Python ä»£ç ï¼Œä»¥è¿›è¡Œåœ¨WMT14æ•°æ®é›†ä¸Šä½¿ç”¨Transformerè¿›è¡Œæ¶ˆèç ”ç©¶çš„å®éªŒã€‚ä»£ç å¿…é¡»éµå¾ªGoogleé£æ ¼æŒ‡å—ã€PEP8è§„èŒƒï¼ŒåŒ…å«PEP257æ–‡æ¡£å­—ç¬¦ä¸²å’Œç±»å‹æ ‡æ³¨ã€‚ä»£ç è¦é«˜æ•ˆï¼ŒåŒ…å«é€‚å½“çš„è¾¹ç•Œæ¡ä»¶æ£€æŸ¥ï¼Œå¹¶èƒ½å¤Ÿæ‰“å°é‡è¦ä¿¡æ¯ã€‚æˆ‘ä»¬æ²¡æœ‰åŠæ³•è¿è¡Œé‡è´Ÿè½½çš„è®­ç»ƒï¼Œä»£ç åº”æ”¯æŒé¢„å¤„ç†å¥½çš„æ•°æ®é›†ï¼Œå¹¶é¿å…è¿‡å¤§æ•°æ®çš„åˆ†å‘ã€‚

æˆ‘åœ¨è€ƒè™‘ä½¿ç”¨ Hugging Face æ•°æ®é›†ï¼Œ"wmt14" æ˜¯å¦å¯ç”¨ï¼Œè¿˜æœ‰å¯èƒ½éœ€è¦é€‰æ‹©æŸäº›å­é›†ï¼ˆå¦‚ en-deï¼‰ã€‚è€ƒè™‘åˆ°æ•°æ®é›†ä¼šå¾ˆå¤§ï¼Œæˆ‘ä¼šé€‰æ‹©ä½¿ç”¨ SentencePiece æˆ– Byte Pair Encoding è¿›è¡Œåˆ†è¯ï¼Œä½†è¿™ä¼šå¢åŠ å¤æ‚åº¦ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ SacreBLEU è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç¡®ä¿ä»£ç å¯ä»¥åœ¨æ²¡æœ‰ç½‘ç»œä¾èµ–çš„æƒ…å†µä¸‹è¿è¡Œã€‚

ä¸ºäº†åŠ è½½WMT14æ•°æ®é›†ï¼Œè‹¥é€šè¿‡ Hugging Face æ— æ³•æ‰¾åˆ°â€œwmt14â€ï¼Œä»£ç åº”æ”¯æŒå›é€€åˆ°æœ¬åœ°è·¯å¾„ã€‚æ¨¡å‹å®ç°æ–¹é¢ï¼Œéœ€è¦ä»é›¶å¼€å§‹æ„å»ºTransformerï¼ŒåŒ…æ‹¬MultiHeadAttentionã€EncoderLayer/DecoderLayerç­‰ï¼Œå¹¶åŠ å…¥ablationè°ƒèŠ‚é¡¹ã€‚å°†æ‰§è¡ŒBLEUè¯„ä¼°ã€è®­ç»ƒå¾ªç¯ï¼Œå¹¶æä¾›æ—¥å¿—è®°å½•ç­‰åŠŸèƒ½ã€‚

åœ¨å®ç°collateå‡½æ•°æ—¶ï¼Œæˆ‘ä»¬å°†ç¡®ä¿åˆ›å»ºç›®æ ‡è¾“å…¥ï¼ˆä½ç§»ï¼‰å’Œæ©ç ã€‚ä»£ç å°†åŒ…å«Chineseæ³¨é‡Šï¼Œå¹¶ä¿è¯å®Œæ•´ã€‚è¿˜ä¼šæ·»åŠ `if __name__ == '__main__':`å…¥å£æ¥è§£æCLIå‚æ•°ã€‚ç”±äºç¯‡å¹…è¾ƒå¤§ï¼Œä»£ç å¯èƒ½éœ€è¦400-600è¡Œï¼Œå¹¶ä¸”æˆ‘ä»¬å°†æ·»åŠ `sanity_check()`ä»¥ç¡®ä¿ä»£ç æ­£ç¡®æ€§ã€‚

å®Œæˆ

ä¸‹é¢ç»™å‡ºä¸€å¥—**å·¥ä¸šçº§**ã€ç»“æ„åŒ–ä¸”å¯æ‰©å±•çš„**Transformer æ¶ˆèå®éªŒ**ä»£ç ï¼ˆåŸºäº WMT14ï¼ŒPyTorch + tensorboardX + loguruï¼‰ã€‚  
ç‰¹ç‚¹ï¼šä¸¥æ ¼éµå¾ª **Google Python Style Guide** + **PEP 8/257**ï¼Œæä¾›**ç±»å‹æ ‡æ³¨**ã€**å…³é”®æ­¥éª¤ä¸­æ–‡æ³¨é‡Š**ã€**è¾¹ç•Œæ£€æŸ¥**ã€**Warmup è°ƒåº¦**ã€**Label Smoothing**ã€**æƒé‡å…±äº«**ã€**å¯åˆ‡æ¢ä½ç½®ç¼–ç ï¼ˆæ­£å¼¦/å¯å­¦ä¹ ï¼‰**ã€**å¤šå¤´æ•°/ç»´åº¦/Dropout æ¶ˆè**ã€**SacreBLEU è¯„ä¼°**ã€**ä¸°å¯Œæ—¥å¿—ä¸å¯è§†åŒ–**ã€**Sanity Check** ç­‰ã€‚

> è¯´æ˜ï¼šæœ¬ä»£ç æ”¯æŒä¸¤ç§æ•°æ®è·¯å¾„ï¼š  
> 1ï¼‰ä¼˜å…ˆå°è¯• HuggingFace `datasets` çš„ `wmt14`ï¼ˆå¦‚ `wmt14 de-en`ï¼‰ï¼Œ  
> 2ï¼‰è‹¥ä¸å¯ç”¨ï¼Œåˆ™ä»æœ¬åœ°è·¯å¾„è¯»å–ï¼ˆéœ€ç”¨æˆ·è‡ªè¡Œå‡†å¤‡å¹³è¡Œè¯­æ–™ï¼‰ã€‚  
> åŒæ—¶å†…ç½® `sentencepiece` è®­ç»ƒ/åŠ è½½ï¼Œä»¥ä¾¿å¤ç°è®ºæ–‡ BPE å­è¯åŒ–æµç¨‹ã€‚

* * *

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Transformer Ablation Study on WMT14 with PyTorch.

This module provides an industrial-grade, end-to-end pipeline to run
ablation studies (as in "Attention is All You Need", Table 3) on the
Transformer architecture, focusing on:
  - Number of attention heads (h)
  - Model hidden dimension (d_model) and feed-forward dimension (d_ff)
  - Dropout rate
  - Positional encoding type (sinusoidal vs. learned)

Key features:
  * Robust engineering: boundary checks, clear class abstractions,
    Google style docstrings (PEP 257), PEP 8 compliance, and typing.
  * Training tricks: Adam + Noam warmup, label smoothing, tied embeddings.
  * Logging & viz: loguru for logs and tensorboardX for metrics.
  * Evaluation: SacreBLEU-based translation quality evaluation.
  * Data: HuggingFace datasets "wmt14" (if available) or local TSV files,
    SentencePiece BPE training or reuse for tokenization.
  * Sanity checks to validate shapes, masks and forward/backward logic.

Author: GPT-5 Thinking
Date: 2025-08-20
"""

from __future__ import annotations

import argparse
import dataclasses
import json
import math
import os
import random
import shutil
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Literal, Optional, Sequence, Tuple

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from loguru import logger
from tensorboardX import SummaryWriter
from torch.utils.data import DataLoader, Dataset

# Optional dependencies:
# datasets: for WMT14 loading. sentencepiece: for BPE tokenizer.
try:
    from datasets import load_dataset, DatasetDict  # type: ignore
    HF_DATASETS_AVAILABLE = True
except Exception:
    HF_DATASETS_AVAILABLE = False

try:
    import sentencepiece as spm  # type: ignore
    SENTENCEPIECE_AVAILABLE = True
except Exception:
    SENTENCEPIECE_AVAILABLE = False

try:
    import sacrebleu  # type: ignore
    SACREBLEU_AVAILABLE = True
except Exception:
    SACREBLEU_AVAILABLE = False

# -----------------------------
# Utilities and Configuration
# -----------------------------

def set_global_seed(seed: int) -> None:
    """Set global random seed for reproducibility.

    Args:
        seed: Random seed.
    """
    # è®¾ç½®å…¨å±€éšæœºç§å­ï¼Œä¿è¯å®éªŒå¯å¤ç°
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

def ensure_dir(path: str | Path, clear_if_exists: bool = False) -> Path:
    """Ensure a directory exists.

    Args:
        path: Directory path.
        clear_if_exists: Whether to clear the directory if exists.

    Returns:
        The directory path as Path.
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼›å¿…è¦æ—¶æ¸…ç©º
    p = Path(path)
    if p.exists() and clear_if_exists:
        shutil.rmtree(p)
    p.mkdir(parents=True, exist_ok=True)
    return p

@dataclass
class ExperimentConfig:
    """Experiment configuration.

    Attributes:
        run_name: Unique run name (used for logging/checkpoints).
        log_dir: TensorBoard & log directory.
        save_dir: Checkpoint directory.
        data_dir: Local data directory fallback (if HF datasets unavailable).
        spm_dir: SentencePiece model dir.
        src_lang: Source language code (e.g., 'en').
        tgt_lang: Target language code (e.g., 'de').
        vocab_size: Subword vocabulary size.
        max_len: Maximum sequence length (tokens).
        batch_size: Tokens per batch (approx; dynamic padding).
        num_epochs: Number of epochs.
        lr: Base learning rate (Noam scaled).
        warmup_steps: Warmup steps for learning rate.
        label_smoothing: Label smoothing epsilon [0, 1).
        dropout: Dropout rate [0, 1).
        d_model: Hidden size (must be divisible by n_heads).
        n_heads: Number of attention heads.
        n_layers: Number of encoder/decoder layers.
        d_ff: Feed-forward hidden size.
        pos_encoding: 'sinusoidal' or 'learned'.
        weight_tying: Weight tying between embedding and generator.
        grad_clip: Gradient clipping norm (0 to disable).
        fp16: Use automatic mixed precision if True.
        save_every: Save checkpoint every N steps.
        log_every: Log every N steps.
        eval_every: Evaluate every N steps.
        num_workers: DataLoader workers.
        seed: Random seed.
        device: 'cuda' or 'cpu'.
        max_train_samples: Optional cap on training samples (debug).
        max_eval_samples: Optional cap on eval samples (debug).
        group: Ablation group tag for aggregation.
    """
    run_name: str = "baseline_en-de"
    log_dir: str = "runs"
    save_dir: str = "checkpoints"
    data_dir: str = "data_wmt14"
    spm_dir: str = "spm_models"
    src_lang: str = "en"
    tgt_lang: str = "de"
    vocab_size: int = 37000
    max_len: int = 256
    batch_size: int = 8192  # åŠ¨æ€padding, ä»¥ tokens æ•°è¿‘ä¼¼
    num_epochs: int = 10
    lr: float = 2.0  # Noam lr factor
    warmup_steps: int = 4000
    label_smoothing: float = 0.1
    dropout: float = 0.1
    d_model: int = 512
    n_heads: int = 8
    n_layers: int = 6
    d_ff: int = 2048
    pos_encoding: Literal["sinusoidal", "learned"] = "sinusoidal"
    weight_tying: bool = True
    grad_clip: float = 1.0
    fp16: bool = True
    save_every: int = 5000
    log_every: int = 100
    eval_every: int = 5000
    num_workers: int = 4
    seed: int = 42
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    max_train_samples: Optional[int] = None
    max_eval_samples: Optional[int] = None
    group: str = "ablation"

# -----------------------------
# Tokenization with SentencePiece
# -----------------------------

class SentencePieceTokenizer:
    """SentencePiece tokenizer wrapper supporting training and inference.

    This wrapper provides encode/decode methods and special token handling.

    Note:
        Requires 'sentencepiece' package installed.

    Attributes:
        model_prefix: Prefix (path) for the SentencePiece model files.
        vocab_size: Vocabulary size.
        character_coverage: Character coverage for training.
        model_type: BPE model type.
        pad_id: Padding token id.
        bos_id: Begin-of-sentence id.
        eos_id: End-of-sentence id.
        unk_id: Unknown token id.
    """

    def __init__(
        self,
        model_prefix: str,
        vocab_size: int = 37000,
        character_coverage: float = 1.0,
        model_type: str = "bpe",
    ) -> None:
        if not SENTENCEPIECE_AVAILABLE:
            raise RuntimeError("sentencepiece is required but not installed.")
        self.model_prefix = model_prefix
        self.vocab_size = vocab_size
        self.character_coverage = character_coverage
        self.model_type = model_type
        self._sp = spm.SentencePieceProcessor()  # type: ignore
        self.pad_id = 0
        self.bos_id = 1
        self.eos_id = 2
        self.unk_id = 3

    def train(
        self,
        input_files: List[str],
        user_defined_symbols: Optional[List[str]] = None,
    ) -> None:
        """Train a SentencePiece model.

        Args:
            input_files: List of input text files for training.
            user_defined_symbols: Optional extra symbols.
        """
        # è®­ç»ƒ SentencePiece æ¨¡å‹ï¼Œç”Ÿæˆ .model/.vocab
        args = {
            "input": ",".join(input_files),
            "model_prefix": self.model_prefix,
            "vocab_size": self.vocab_size,
            "character_coverage": self.character_coverage,
            "model_type": self.model_type,
            "pad_id": self.pad_id,
            "bos_id": self.bos_id,
            "eos_id": self.eos_id,
            "unk_id": self.unk_id,
        }
        if user_defined_symbols:
            args["user_defined_symbols"] = ",".join(user_defined_symbols)
        spm.SentencePieceTrainer.Train(**args)  # type: ignore

    def load(self) -> None:
        """Load an existing SentencePiece model."""
        # åŠ è½½å·²è®­ç»ƒçš„ SPM æ¨¡å‹
        model_file = f"{self.model_prefix}.model"
        if not os.path.exists(model_file):
            raise FileNotFoundError(f"SentencePiece model not found: {model_file}")
        self._sp.Load(model_file)  # type: ignore

    def encode(self, text: str, add_bos: bool = True, add_eos: bool = True) -> List[int]:
        """Encode text to a list of token ids.

        Args:
            text: Input string.
            add_bos: Prepend BOS token if True.
            add_eos: Append EOS token if True.

        Returns:
            List of token ids.
        """
        # ç¼–ç æ–‡æœ¬ä¸º token id åˆ—è¡¨
        ids = self._sp.EncodeAsIds(text)  # type: ignore
        if add_bos:
            ids = [self.bos_id] + ids
        if add_eos:
            ids = ids + [self.eos_id]
        return ids

    def decode(self, ids: List[int]) -> str:
        """Decode token ids to text.

        Args:
            ids: Token id list.

        Returns:
            Decoded string.
        """
        # å°† token id åˆ—è¡¨è§£ç ä¸ºå­—ç¬¦ä¸²
        return self._sp.DecodeIds(ids)  # type: ignore

    @property
    def vocab_size_(self) -> int:
        """Return vocabulary size including special tokens."""
        return self._sp.GetPieceSize()  # type: ignore

# -----------------------------
# Dataset and DataModule
# -----------------------------

class TranslationExample(Dataset):
    """PyTorch dataset for tokenized parallel examples."""

    def __init__(
        self,
        src: List[List[int]],
        tgt: List[List[int]],
        max_len: int,
    ) -> None:
        # å­˜å‚¨å·²åˆ†è¯çš„æº/ç›®æ ‡åºåˆ—
        self.src = src
        self.tgt = tgt
        self.max_len = max_len

    def __len__(self) -> int:
        return len(self.src)

    def __getitem__(self, index: int) -> Tuple[List[int], List[int]]:
        # è¿”å›å•ä¸ªæ ·æœ¬çš„ (src_ids, tgt_ids)
        s = self.src[index][: self.max_len]
        t = self.tgt[index][: self.max_len]
        return s, t

class DynamicBatchCollator:
    """Dynamic padding and mask creation for Transformer training."""

    def __init__(self, pad_id: int, device: torch.device) -> None:
        # collate å‡½æ•°ï¼šæ ¹æ® batch åºåˆ—æœ€é•¿é•¿åº¦è¿›è¡ŒåŠ¨æ€ padding
        self.pad_id = pad_id
        self.device = device

    def _pad(self, sequences: List[List[int]]) -> Tuple[torch.Tensor, torch.Tensor]:
        # å¯¹ä¸ç­‰é•¿åºåˆ—è¿›è¡Œ paddingï¼Œå¹¶è¿”å› mask
        max_len = max(len(s) for s in sequences)
        batch = len(sequences)
        tensor = torch.full((batch, max_len), fill_value=self.pad_id, dtype=torch.long)
        for i, seq in enumerate(sequences):
            tensor[i, : len(seq)] = torch.tensor(seq, dtype=torch.long)
        # padding mask: True indicates padding positions
        pad_mask = (tensor == self.pad_id)
        return tensor, pad_mask

    def _subsequent_mask(self, size: int) -> torch.Tensor:
        # ä¸‹ä¸‰è§’ maskï¼Œé˜²æ­¢ decoder çœ‹åˆ°æœªæ¥ä½ç½®
        attn_shape = (1, size, size)
        subsequent_mask = torch.triu(torch.ones(attn_shape, dtype=torch.bool), diagonal=1)
        return subsequent_mask  # shape: (1, T, T)

    def __call__(
        self, batch: List[Tuple[List[int], List[int]]]
    ) -> Dict[str, torch.Tensor]:
        # ç»„è£… batchï¼Œå¹¶ç”Ÿæˆæ¨¡å‹æ‰€éœ€çš„ mask
        src_list, tgt_list = zip(*batch)
        src, src_pad_mask = self._pad(list(src_list))
        tgt, tgt_pad_mask = self._pad(list(tgt_list))

        # è®­ç»ƒæ—¶å°† tgt åˆ†æˆè¾“å…¥ (tgt_in) ä¸ label (tgt_out)
        # ä¾‹å¦‚: [BOS, y1, y2, ..., y_{n-1}] -> è¾“å…¥
        #       [y1, y2, ..., y_{n-1}, EOS] -> æ ‡ç­¾
        tgt_in = tgt[:, :-1].contiguous()
        tgt_out = tgt[:, 1:].contiguous()

        # subsequent mask ä¸ pad mask ç»„åˆ
        seq_len = tgt_in.size(1)
        subsequent = self._subsequent_mask(seq_len).to(self.device)
        # æ³¨æ„ï¼šTransformer é‡Œçš„ key_padding_mask è¯­ä¹‰ä¸º True è¡¨ç¤º padding
        # å¯¹ decoder self-attention çš„ mask éœ€è¦åŒæ—¶è€ƒè™‘ pad å’Œ subsequent
        src_key_padding_mask = src_pad_mask.to(self.device)  # (B, S)
        tgt_key_padding_mask = tgt_pad_mask[:, :-1].to(self.device)  # (B, T)
        tgt_mask = subsequent  # (1, T, T)

        return {
            "src": src.to(self.device),
            "tgt_in": tgt_in.to(self.device),
            "tgt_out": tgt_out.to(self.device),
            "src_key_padding_mask": src_key_padding_mask,
            "tgt_key_padding_mask": tgt_key_padding_mask,
            "tgt_mask": tgt_mask,
        }

class WMT14DataModule:
    """Data module to orchestrate loading, tokenization, and dataloaders.

    This supports HF datasets (if available) or local TSV files with columns:
    src \t tgt

    Attributes:
        cfg: Experiment configuration.
        sp_src: SentencePiece tokenizer for source language.
        sp_tgt: SentencePiece tokenizer for target language.
    """

    def __init__(self, cfg: ExperimentConfig) -> None:
        self.cfg = cfg
        self.sp_src: Optional[SentencePieceTokenizer] = None
        self.sp_tgt: Optional[SentencePieceTokenizer] = None
        self.ds_train: Optional[TranslationExample] = None
        self.ds_valid: Optional[TranslationExample] = None
        self.ds_test: Optional[TranslationExample] = None

    def _maybe_train_or_load_spm(
        self,
        src_corpus_files: List[str],
        tgt_corpus_files: List[str],
    ) -> None:
        # è®­ç»ƒæˆ–åŠ è½½ SentencePiece æ¨¡å‹ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
        ensure_dir(self.cfg.spm_dir)
        src_prefix = str(Path(self.cfg.spm_dir) / f"spm_{self.cfg.src_lang}")
        tgt_prefix = str(Path(self.cfg.spm_dir) / f"spm_{self.cfg.tgt_lang}")

        self.sp_src = SentencePieceTokenizer(
            src_prefix, vocab_size=self.cfg.vocab_size
        )
        self.sp_tgt = SentencePieceTokenizer(
            tgt_prefix, vocab_size=self.cfg.vocab_size
        )

        # è‹¥æ¨¡å‹å·²å­˜åœ¨åˆ™ç›´æ¥åŠ è½½ï¼Œå¦åˆ™è®­ç»ƒ
        if not os.path.exists(f"{src_prefix}.model") or not os.path.exists(
            f"{tgt_prefix}.model"
        ):
            logger.info("Training SentencePiece models for src/tgt ...")
            self.sp_src.train(src_corpus_files)
            self.sp_tgt.train(tgt_corpus_files)
        else:
            logger.info("Loading existing SentencePiece models for src/tgt ...")

        self.sp_src.load()
        self.sp_tgt.load()

    def _load_hf_wmt14(self) -> Tuple[List[str], List[str], List[str], List[str], List[str], List[str]]:
        """Load WMT14 via HuggingFace datasets if available.

        Returns:
            (train_src, train_tgt, valid_src, valid_tgt, test_src, test_tgt)
        """
        # ä½¿ç”¨ HF datasets åŠ è½½ WMT14ï¼ˆè‹¥å¯ç”¨ï¼‰
        # ä¸ºäº†å…¼å®¹æ€§ï¼Œè¿™é‡Œå°è¯•å‡ ç§é…ç½®åç§°
        configs_try = [
            (f"{self.cfg.src_lang}-{self.cfg.tgt_lang}", self.cfg.src_lang, self.cfg.tgt_lang),
            (f"{self.cfg.tgt_lang}-{self.cfg.src_lang}", self.cfg.tgt_lang, self.cfg.src_lang),
        ]
        last_exc = None
        for config_name, src, tgt in configs_try:
            try:
                dsd: DatasetDict = load_dataset("wmt14", config_name)  # type: ignore
                # datasets å­—æ®µå¯èƒ½ä¸º 'translation' æˆ– 'translation' é”®ä¸‹å­—å…¸
                def _extract_pairs(split_name: str) -> Tuple[List[str], List[str]]:
                    split = dsd[split_name]
                    xs, ys = [], []
                    for ex in split:
                        # HF wmt14 é€šå¸¸æä¾› ex['translation'] = {src_lang: str, tgt_lang: str}
                        titem = ex["translation"]
                        xs.append(titem[src])
                        ys.append(titem[tgt])
                    return xs, ys

                train_x, train_y = _extract_pairs("train")
                valid_x, valid_y = _extract_pairs("validation") if "validation" in dsd else _extract_pairs("test")
                test_x, test_y = _extract_pairs("test")

                # è‹¥é…ç½®é¡ºåºä¸æœŸæœ›ç›¸åï¼Œåˆ™äº¤æ¢
                if src != self.cfg.src_lang:
                    # äº¤æ¢å›æˆ‘ä»¬çš„å®šä¹‰
                    train_x, train_y = train_y, train_x
                    valid_x, valid_y = valid_y, valid_x
                    test_x, test_y = test_y, test_x

                return train_x, train_y, valid_x, valid_y, test_x, test_y
            except Exception as e:  # noqa: BLE001
                last_exc = e
                continue
        raise RuntimeError(
            f"Failed to load WMT14 via datasets. Last error: {last_exc}"
        )

    def _load_local_parallel(
        self,
        split: str,
    ) -> Tuple[List[str], List[str]]:
        """Load local TSV parallel data for a split.

        Args:
            split: One of 'train', 'valid', 'test'.

        Returns:
            (src_texts, tgt_texts)
        """
        # ä»æœ¬åœ° TSV è¯»å–å¹³è¡Œè¯­æ–™ï¼Œæ ¼å¼: src \t tgt
        file_path = Path(self.cfg.data_dir) / f"{split}.{self.cfg.src_lang}-{self.cfg.tgt_lang}.tsv"
        if not file_path.exists():
            raise FileNotFoundError(f"Local data file not found: {file_path}")
        xs, ys = [], []
        with open(file_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                parts = line.split("\t")
                if len(parts) != 2:
                    # è·³è¿‡éæ³•è¡Œ
                    continue
                xs.append(parts[0])
                ys.append(parts[1])
        return xs, ys

    def prepare(self) -> None:
        """Prepare tokenizers and datasets."""
        # å‡†å¤‡æ•°æ®ï¼šåŠ è½½æ–‡æœ¬ã€ï¼ˆè®­ç»ƒæˆ–åŠ è½½ï¼‰SPMã€ç¼–ç ã€æ„é€ Dataset
        logger.info("Preparing data module ...")

        if HF_DATASETS_AVAILABLE:
            try:
                train_x, train_y, valid_x, valid_y, test_x, test_y = self._load_hf_wmt14()
                logger.info("Loaded WMT14 from HuggingFace datasets.")
            except Exception as e:  # noqa: BLE001
                logger.warning(f"HF datasets loading failed: {e}. Falling back to local files.")
                train_x, train_y = self._load_local_parallel("train")
                valid_x, valid_y = self._load_local_parallel("valid")
                test_x, test_y = self._load_local_parallel("test")
        else:
            logger.warning("datasets not available. Using local files.")
            train_x, train_y = self._load_local_parallel("train")
            valid_x, valid_y = self._load_local_parallel("valid")
            test_x, test_y = self._load_local_parallel("test")

        # é™åˆ¶æ ·æœ¬æ•°ï¼ˆè°ƒè¯•/å¿«é€Ÿè¿è¡Œï¼‰
        if self.cfg.max_train_samples:
            train_x, train_y = train_x[: self.cfg.max_train_samples], train_y[: self.cfg.max_train_samples]
        if self.cfg.max_eval_samples:
            valid_x, valid_y = valid_x[: self.cfg.max_eval_samples], valid_y[: self.cfg.max_eval_samples]
            test_x, test_y = test_x[: self.cfg.max_eval_samples], test_y[: self.cfg.max_eval_samples]

        # è®­ç»ƒ/åŠ è½½ SentencePiece
        if not SENTENCEPIECE_AVAILABLE:
            raise RuntimeError("sentencepiece is required for BPE tokenization.")
        ensure_dir(self.cfg.spm_dir)
        # ä¸ºäº†æ›´ç¨³å¦¥ï¼ŒSPM ç”¨å®Œæ•´è®­ç»ƒé›†è®­ç»ƒ
        src_tmp = str(Path(self.cfg.spm_dir) / f"tmp_src_{self.cfg.src_lang}.txt")
        tgt_tmp = str(Path(self.cfg.spm_dir) / f"tmp_tgt_{self.cfg.tgt_lang}.txt")
        with open(src_tmp, "w", encoding="utf-8") as f:
            for s in train_x:
                f.write(s.strip() + "\n")
        with open(tgt_tmp, "w", encoding="utf-8") as f:
            for s in train_y:
                f.write(s.strip() + "\n")
        self._maybe_train_or_load_spm([src_tmp], [tgt_tmp])
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(src_tmp)
            os.remove(tgt_tmp)
        except Exception:
            pass

        assert self.sp_src is not None and self.sp_tgt is not None

        # ç¼–ç æ–‡æœ¬ä¸º token åºåˆ—
        def _encode_corpus(xs: List[str], ys: List[str]) -> Tuple[List[List[int]], List[List[int]]]:
            src_tok = [self.sp_src.encode(x) for x in xs]
            tgt_tok = [self.sp_tgt.encode(y) for y in ys]
            return src_tok, tgt_tok

        train_src_tok, train_tgt_tok = _encode_corpus(train_x, train_y)
        valid_src_tok, valid_tgt_tok = _encode_corpus(valid_x, valid_y)
        test_src_tok, test_tgt_tok = _encode_corpus(test_x, test_y)

        # æ„é€  PyTorch Dataset
        self.ds_train = TranslationExample(train_src_tok, train_tgt_tok, self.cfg.max_len)
        self.ds_valid = TranslationExample(valid_src_tok, valid_tgt_tok, self.cfg.max_len)
        self.ds_test = TranslationExample(test_src_tok, test_tgt_tok, self.cfg.max_len)

        logger.info(
            f"Prepared datasets: train={len(self.ds_train)} valid={len(self.ds_valid)} test={len(self.ds_test)}"
        )

    def create_dataloaders(self) -> Tuple[DataLoader, DataLoader, DataLoader]:
        """Create dataloaders for train/valid/test.

        Returns:
            Tuple of train_loader, valid_loader, test_loader.
        """
        assert self.ds_train and self.ds_valid and self.ds_test
        device = torch.device(self.cfg.device)
        collate = DynamicBatchCollator(pad_id=0, device=device)

        # æ³¨æ„ï¼šè¿™é‡Œ batch_size æ˜¯å¥å­æ•°ï¼›ç”±äºæˆ‘ä»¬ä½¿ç”¨åŠ¨æ€ paddingï¼Œ
        # è‹¥æƒ³æ›´è¿‘ä¼¼â€œæŒ‰tokenæ•°â€æ§åˆ¶ï¼Œå¯æ”¹é€ ä¸ºåŠ¨æ€é‡‡æ ·å™¨ï¼ˆæ­¤å¤„é‡‡ç”¨å›ºå®šbatchç®€åŒ–ï¼‰ã€‚
        train_loader = DataLoader(
            self.ds_train,
            batch_size=max(1, self.cfg.batch_size // 128),  # ç»éªŒä¼°è®¡ï¼Œé¿å…OOM
            shuffle=True,
            num_workers=self.cfg.num_workers,
            collate_fn=collate,
            pin_memory=True,
            drop_last=True,
        )
        valid_loader = DataLoader(
            self.ds_valid,
            batch_size=max(1, self.cfg.batch_size // 256),
            shuffle=False,
            num_workers=self.cfg.num_workers,
            collate_fn=collate,
            pin_memory=True,
            drop_last=False,
        )
        test_loader = DataLoader(
            self.ds_test,
            batch_size=max(1, self.cfg.batch_size // 256),
            shuffle=False,
            num_workers=self.cfg.num_workers,
            collate_fn=collate,
            pin_memory=True,
            drop_last=False,
        )
        return train_loader, valid_loader, test_loader

# -----------------------------
# Model Components
# -----------------------------

class SinusoidalPositionalEncoding(nn.Module):
    """Sinusoidal positional encoding as in Vaswani et al. 2017."""

    def __init__(self, d_model: int, max_len: int = 10000) -> None:
        super().__init__()
        # é¢„è®¡ç®—æ­£å¼¦ä½ç½®ç¼–ç çŸ©é˜µï¼Œé¿å…é‡å¤è®¡ç®—
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)
        div_term = torch.exp(
            torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model)
        )
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        # æ³¨å†Œä¸º bufferï¼Œä¸å‚ä¸è®­ç»ƒ
        self.register_buffer("pe", pe)  # shape: (max_len, d_model)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Add positional encodings to input.

        Args:
            x: Input tensor with shape (B, T, D)

        Returns:
            Tensor with positional encodings added (B, T, D).
        """
        # å°†é¢„è®¡ç®—çš„ä½ç½®ç¼–ç åŠ åˆ°è¾“å…¥ï¼Œä¿æŒ shape ä¸å˜
        bsz, seq_len, d_model = x.size()
        x = x + self.pe[:seq_len].unsqueeze(0)
        return x

class LearnedPositionalEncoding(nn.Embedding):
    """Learned positional embedding."""

    def __init__(self, max_len: int, d_model: int) -> None:
        super().__init__(max_len, d_model)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Add learned positional embeddings.

        Args:
            x: Input tensor with shape (B, T, D)

        Returns:
            Tensor with positional embeddings added (B, T, D).
        """
        bsz, seq_len, d_model = x.size()
        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).repeat(bsz, 1)
        pos_embed = super().forward(positions)  # (B, T, D)
        return x + pos_embed

class LabelSmoothingLoss(nn.Module):
    """Label smoothing loss for sequence-to-sequence tasks."""

    def __init__(self, vocab_size: int, smoothing: float, ignore_index: int = 0) -> None:
        super().__init__()
        if not (0.0 <= smoothing < 1.0):
            raise ValueError("label_smoothing must be in [0,1).")
        # Label Smoothing: å°† one-hot æ ‡ç­¾åˆ†é…å°‘é‡æ¦‚ç‡ç»™å…¶ä»–ç±»
        self.ignore_index = ignore_index
        self.smoothing = smoothing
        self.confidence = 1.0 - smoothing
        self.vocab_size = vocab_size

    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """Compute smoothed cross-entropy.

        Args:
            pred: Logits of shape (B*T, V).
            target: Target token ids of shape (B*T,).

        Returns:
            Loss scalar tensor.
        """
        # å¿½ç•¥ padding çš„ä½ç½®
        mask = (target != self.ignore_index)
        target = target[mask]
        pred = pred[mask]
        if pred.numel() == 0:
            return pred.new_tensor(0.0)

        # æ„é€ å¹³æ»‘åˆ†å¸ƒ
        with torch.no_grad():
            true_dist = torch.full_like(pred, fill_value=self.smoothing / (self.vocab_size - 1))
            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)
        loss = F.kl_div(F.log_softmax(pred, dim=-1), true_dist, reduction="batchmean")
        return loss

class NoamScheduler(torch.optim.lr_scheduler._LRScheduler):
    """Noam learning rate scheduler from Vaswani et al. (2017)."""

    def __init__(self, optimizer: torch.optim.Optimizer, d_model: int, warmup_steps: int, last_epoch: int = -1) -> None:
        self.d_model = d_model
        self.warmup_steps = warmup_steps
        super().__init__(optimizer, last_epoch)

    def get_lr(self) -> List[float]:
        # æ ¹æ® step åŠ¨æ€è®¡ç®—å­¦ä¹ ç‡ï¼Œwarmup åæŒ‰ 1/sqrt(step) è¡°å‡
        step = max(1, self.last_epoch + 1)
        scale = (self.d_model ** -0.5) * min(step ** -0.5, step * (self.warmup_steps ** -1.5))
        return [base_lr * scale for base_lr in self.base_lrs]

class TransformerSeq2Seq(nn.Module):
    """Transformer Seq2Seq model wrapping nn.Transformer with custom embeddings/PE.

    Supports:
      - Sinusoidal or learned positional encodings
      - Weight tying (encoder/decoder emb <-> generator)
    """

    def __init__(
        self,
        vocab_src: int,
        vocab_tgt: int,
        d_model: int,
        n_heads: int,
        n_layers: int,
        d_ff: int,
        dropout: float,
        max_len: int,
        pos_encoding: Literal["sinusoidal", "learned"] = "sinusoidal",
        weight_tying: bool = True,
    ) -> None:
        super().__init__()
        if d_model % n_heads != 0:
            raise ValueError("d_model must be divisible by n_heads.")
        if not (0.0 <= dropout < 1.0):
            raise ValueError("dropout must be in [0,1).")

        # Embeddings
        self.src_embed = nn.Embedding(vocab_src, d_model, padding_idx=0)
        self.tgt_embed = nn.Embedding(vocab_tgt, d_model, padding_idx=0)

        # Positional Encoding
        if pos_encoding == "sinusoidal":
            self.pos_enc = SinusoidalPositionalEncoding(d_model, max_len=max_len)
        elif pos_encoding == "learned":
            self.pos_enc = LearnedPositionalEncoding(max_len=max_len, d_model=d_model)
        else:
            raise ValueError("pos_encoding must be 'sinusoidal' or 'learned'.")

        # Core Transformer
        self.transformer = nn.Transformer(
            d_model=d_model,
            nhead=n_heads,
            num_encoder_layers=n_layers,
            num_decoder_layers=n_layers,
            dim_feedforward=d_ff,
            dropout=dropout,
            batch_first=True,  # ä½¿ç”¨ (B, T, D) æ¥å£
            norm_first=False,  # ä¸åŸè®ºæ–‡åå½’ä¸€åŒ–ä¸€è‡´
        )

        # Generator (pre-softmax linear)
        self.generator = nn.Linear(d_model, vocab_tgt, bias=False)

        # Weight tying
        if weight_tying:
            if self.tgt_embed.weight.size() != self.generator.weight.size():
                raise ValueError("Weight tying requires tgt_embed and generator to have same shape.")
            self.generator.weight = self.tgt_embed.weight  # weight tying

        # Initialization
        self._reset_parameters()

    def _reset_parameters(self) -> None:
        # å‚æ•°åˆå§‹åŒ–ï¼ˆXavierï¼‰
        for p in self.parameters():
            if p.dim() > 1:
                nn.init.xavier_uniform_(p)

    def encode(self, src_ids: torch.Tensor, src_key_padding_mask: torch.Tensor) -> torch.Tensor:
        """Encode source sequence.

        Args:
            src_ids: Source token ids (B, S).
            src_key_padding_mask: Padding mask (B, S), True for PAD positions.

        Returns:
            Encoder memory tensor (B, S, D).
        """
        src_emb = self.src_embed(src_ids) * math.sqrt(self.transformer.d_model)
        src_emb = self.pos_enc(src_emb)
        memory = self.transformer.encoder(
            src_emb,
            src_key_padding_mask=src_key_padding_mask,  # True è¡¨ç¤º padding
        )
        return memory

    def decode(
        self,
        tgt_in: torch.Tensor,
        memory: torch.Tensor,
        tgt_mask: torch.Tensor,
        tgt_key_padding_mask: torch.Tensor,
        memory_key_padding_mask: torch.Tensor,
    ) -> torch.Tensor:
        """Decode target sequence given encoder memory.

        Args:
            tgt_in: Target input ids (B, T).
            memory: Encoder memory (B, S, D).
            tgt_mask: Causal mask for decoder self-attention (T, T) or (1, T, T).
            tgt_key_padding_mask: Padding mask for target (B, T).
            memory_key_padding_mask: Padding mask for source (B, S).

        Returns:
            Decoder output logits (B, T, V).
        """
        tgt_emb = self.tgt_embed(tgt_in) * math.sqrt(self.transformer.d_model)
        tgt_emb = self.pos_enc(tgt_emb)
        out = self.transformer.decoder(
            tgt=tgt_emb,
            memory=memory,
            tgt_mask=tgt_mask[0],  # (T, T)
            tgt_key_padding_mask=tgt_key_padding_mask,
            memory_key_padding_mask=memory_key_padding_mask,
        )
        logits = self.generator(out)  # (B, T, V)
        return logits

    def forward(
        self,
        src_ids: torch.Tensor,
        tgt_in: torch.Tensor,
        tgt_mask: torch.Tensor,
        src_key_padding_mask: torch.Tensor,
        tgt_key_padding_mask: torch.Tensor,
    ) -> torch.Tensor:
        """Forward pass for training.

        Args:
            src_ids: Source token ids (B, S).
            tgt_in: Target input ids (B, T).
            tgt_mask: Causal mask (1, T, T).
            src_key_padding_mask: Source padding mask (B, S).
            tgt_key_padding_mask: Target padding mask (B, T).

        Returns:
            Logits (B, T, V).
        """
        memory = self.encode(src_ids, src_key_padding_mask)
        logits = self.decode(
            tgt_in=tgt_in,
            memory=memory,
            tgt_mask=tgt_mask,
            tgt_key_padding_mask=tgt_key_padding_mask,
            memory_key_padding_mask=src_key_padding_mask,
        )
        return logits

    @torch.no_grad()
    def greedy_decode(
        self,
        src_ids: torch.Tensor,
        src_key_padding_mask: torch.Tensor,
        max_len: int,
        bos_id: int,
        eos_id: int,
    ) -> torch.Tensor:
        """Greedy decoding for inference.

        Args:
            src_ids: Source ids (B, S).
            src_key_padding_mask: Source padding mask (B, S).
            max_len: Max generation length.
            bos_id: BOS token id.
            eos_id: EOS token id.

        Returns:
            Generated ids (B, T_out).
        """
        # è´ªå¿ƒè§£ç ï¼Œé€æ­¥ç”Ÿæˆï¼Œç›´åˆ° EOS æˆ–è¾¾åˆ°æœ€å¤§é•¿åº¦
        device = src_ids.device
        memory = self.encode(src_ids, src_key_padding_mask)
        B = src_ids.size(0)
        ys = torch.full((B, 1), bos_id, dtype=torch.long, device=device)
        finished = torch.zeros(B, dtype=torch.bool, device=device)

        for _ in range(max_len - 1):
            T = ys.size(1)
            subsequent_mask = torch.triu(
                torch.ones((T, T), device=device, dtype=torch.bool), diagonal=1
            ).unsqueeze(0)  # (1, T, T)
            logits = self.decode(
                tgt_in=ys,
                memory=memory,
                tgt_mask=subsequent_mask,
                tgt_key_padding_mask=torch.zeros((B, T), dtype=torch.bool, device=device),
                memory_key_padding_mask=src_key_padding_mask,
            )
            next_token = torch.argmax(logits[:, -1, :], dim=-1)  # (B,)
            ys = torch.cat([ys, next_token.unsqueeze(1)], dim=1)
            finished = finished | (next_token == eos_id)
            if torch.all(finished):
                break
        return ys

# -----------------------------
# Trainer
# -----------------------------

class Trainer:
    """Trainer handling training loop, evaluation, and logging."""

    def __init__(self, cfg: ExperimentConfig, data: WMT14DataModule) -> None:
        self.cfg = cfg
        self.data = data
        self.device = torch.device(cfg.device)
        self.writer: Optional[SummaryWriter] = None
        self.global_step = 0

        # åˆå§‹åŒ–æ—¥å¿—ä¸ç›®å½•
        ensure_dir(cfg.log_dir)
        ensure_dir(cfg.save_dir)
        self.run_dir = ensure_dir(Path(cfg.log_dir) / cfg.group / cfg.run_name, clear_if_exists=False)
        self.ckpt_dir = ensure_dir(Path(cfg.save_dir) / cfg.group / cfg.run_name, clear_if_exists=False)

    def _build_model_and_optim(self) -> Tuple[TransformerSeq2Seq, torch.optim.Optimizer, NoamScheduler]:
        assert self.data.sp_src is not None and self.data.sp_tgt is not None
        vocab_src = self.data.sp_src.vocab_size_
        vocab_tgt = self.data.sp_tgt.vocab_size_
        logger.info(f"Vocab sizes -> src: {vocab_src} tgt: {vocab_tgt}")

        model = TransformerSeq2Seq(
            vocab_src=vocab_src,
            vocab_tgt=vocab_tgt,
            d_model=self.cfg.d_model,
            n_heads=self.cfg.n_heads,
            n_layers=self.cfg.n_layers,
            d_ff=self.cfg.d_ff,
            dropout=self.cfg.dropout,
            max_len=self.cfg.max_len,
            pos_encoding=self.cfg.pos_encoding,
            weight_tying=self.cfg.weight_tying,
        ).to(self.device)

        optimizer = torch.optim.Adam(model.parameters(), lr=self.cfg.lr, betas=(0.9, 0.98), eps=1e-9)
        scheduler = NoamScheduler(optimizer, d_model=self.cfg.d_model, warmup_steps=self.cfg.warmup_steps)

        return model, optimizer, scheduler

    def _evaluate_bleu(self, model: TransformerSeq2Seq, loader: DataLoader) -> float:
        # ä½¿ç”¨ SacreBLEU å¯¹éªŒè¯é›†/æµ‹è¯•é›†è¿›è¡Œè¯„ä¼°
        if not SACREBLEU_AVAILABLE:
            logger.warning("sacrebleu not installed; returning 0.0 as BLEU.")
            return 0.0
        assert self.data.sp_tgt is not None and self.data.sp_src is not None
        refs: List[str] = []
        hyps: List[str] = []
        model.eval()
        with torch.no_grad():
            for batch in loader:
                src = batch["src"]
                src_kpm = batch["src_key_padding_mask"]
                # è´ªå¿ƒè§£ç ï¼ˆå¯æ‰©å±• beam searchï¼‰
                gen = model.greedy_decode(
                    src_ids=src,
                    src_key_padding_mask=src_kpm,
                    max_len=self.cfg.max_len,
                    bos_id=self.data.sp_tgt.bos_id,
                    eos_id=self.data.sp_tgt.eos_id,
                )
                # å– batch ä¸­çš„å‚è€ƒ/å‡è®¾å¥å­ï¼ˆå»æ‰BOSï¼‰
                tgt_out = batch["tgt_out"].cpu().tolist()
                gen_out = gen.cpu().tolist()
                for ref_ids, hyp_ids in zip(tgt_out, gen_out):
                    # å»é™¤ padding ä¸ è¶…å‡º eos çš„éƒ¨åˆ†
                    ref_ids_clean = [tid for tid in ref_ids if tid not in (0,)]
                    hyp_ids_clean = [tid for tid in hyp_ids if tid not in (0,)]
                    # å»æ‰èµ·å§‹ BOS
                    if len(hyp_ids_clean) > 0 and hyp_ids_clean[0] == self.data.sp_tgt.bos_id:
                        hyp_ids_clean = hyp_ids_clean[1:]
                    # æˆªæ–­è‡³ EOS
                    if self.data.sp_tgt.eos_id in hyp_ids_clean:
                        idx = hyp_ids_clean.index(self.data.sp_tgt.eos_id)
                        hyp_ids_clean = hyp_ids_clean[: idx + 1]
                    ref_text = self.data.sp_tgt.decode(ref_ids_clean)
                    hyp_text = self.data.sp_tgt.decode(hyp_ids_clean)
                    refs.append(ref_text)
                    hyps.append(hyp_text)

        bleu = sacrebleu.corpus_bleu(hyps, [refs]).score  # type: ignore
        return float(bleu)

    def train(self) -> Dict[str, Any]:
        """Run full training with periodic evaluation and checkpointing."""
        train_loader, valid_loader, test_loader = self.data.create_dataloaders()
        model, optimizer, scheduler = self._build_model_and_optim()
        criterion = LabelSmoothingLoss(
            vocab_size=self.data.sp_tgt.vocab_size_,
            smoothing=self.cfg.label_smoothing,
            ignore_index=0,
        )

        self.writer = SummaryWriter(logdir=str(self.run_dir))

        # æ··åˆç²¾åº¦
        scaler = torch.cuda.amp.GradScaler(enabled=self.cfg.fp16)

        logger.info(f"Start training: epochs={self.cfg.num_epochs}, device={self.cfg.device}")
        best_valid_bleu = -1.0
        best_ckpt_path = None
        start_time = time.time()

        for epoch in range(1, self.cfg.num_epochs + 1):
            model.train()
            epoch_loss = 0.0
            step_in_epoch = 0

            for batch in train_loader:
                self.global_step += 1
                step_in_epoch += 1

                src = batch["src"]
                tgt_in = batch["tgt_in"]
                tgt_out = batch["tgt_out"]
                src_kpm = batch["src_key_padding_mask"]
                tgt_kpm = batch["tgt_key_padding_mask"]
                tgt_mask = batch["tgt_mask"]

                optimizer.zero_grad(set_to_none=True)

                with torch.cuda.amp.autocast(enabled=self.cfg.fp16):
                    logits = model(
                        src_ids=src,
                        tgt_in=tgt_in,
                        tgt_mask=tgt_mask,
                        src_key_padding_mask=src_kpm,
                        tgt_key_padding_mask=tgt_kpm,
                    )
                    # å±•å¹³è®¡ç®—äº¤å‰ç†µ/æ ‡ç­¾å¹³æ»‘
                    B, T, V = logits.shape
                    loss = criterion(
                        logits.reshape(B * T, V),
                        tgt_out.reshape(B * T),
                    )

                scaler.scale(loss).backward()
                if self.cfg.grad_clip and self.cfg.grad_clip > 0.0:
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), self.cfg.grad_clip)
                scaler.step(optimizer)
                scaler.update()
                scheduler.step()

                epoch_loss += loss.item()

                if self.global_step % self.cfg.log_every == 0:
                    cur_lr = scheduler.get_last_lr()[0]
                    avg_loss = epoch_loss / step_in_epoch
                    logger.info(
                        f"step={self.global_step} epoch={epoch} step_in_epoch={step_in_epoch} "
                        f"loss={loss.item():.4f} avg_loss={avg_loss:.4f} lr={cur_lr:.6e}"
                    )
                    assert self.writer is not None
                    self.writer.add_scalar("train/loss", loss.item(), self.global_step)
                    self.writer.add_scalar("train/lr", cur_lr, self.global_step)

                if self.global_step % self.cfg.eval_every == 0:
                    valid_bleu = self._evaluate_bleu(model, valid_loader)
                    logger.info(f"[Eval] step={self.global_step} valid_BLEU={valid_bleu:.2f}")
                    assert self.writer is not None
                    self.writer.add_scalar("valid/BLEU", valid_bleu, self.global_step)

                    # Save best
                    if valid_bleu > best_valid_bleu:
                        best_valid_bleu = valid_bleu
                        best_ckpt_path = Path(self.ckpt_dir) / f"best_step{self.global_step}.pt"
                        torch.save(
                            {
                                "model": model.state_dict(),
                                "optimizer": optimizer.state_dict(),
                                "scheduler": scheduler.state_dict(),
                                "config": dataclasses.asdict(self.cfg),
                                "global_step": self.global_step,
                            },
                            str(best_ckpt_path),
                        )
                        logger.info(f"Saved best checkpoint to {best_ckpt_path}")

                if self.global_step % self.cfg.save_every == 0:
                    ckpt_path = Path(self.ckpt_dir) / f"ckpt_step{self.global_step}.pt"
                    torch.save(
                        {"model": model.state_dict(), "global_step": self.global_step},
                        str(ckpt_path),
                    )
                    logger.info(f"Saved checkpoint to {ckpt_path}")

            # æ¯ä¸ª epoch ç»“æŸï¼Œåšä¸€æ¬¡è¯„ä¼°
            valid_bleu = self._evaluate_bleu(model, valid_loader)
            logger.info(f"[EpochEnd] epoch={epoch} valid_BLEU={valid_bleu:.2f}")
            assert self.writer is not None
            self.writer.add_scalar("valid/BLEU_epoch", valid_bleu, epoch)

            if valid_bleu > best_valid_bleu:
                best_valid_bleu = valid_bleu
                best_ckpt_path = Path(self.ckpt_dir) / f"best_epoch{epoch}.pt"
                torch.save(
                    {
                        "model": model.state_dict(),
                        "optimizer": optimizer.state_dict(),
                        "scheduler": scheduler.state_dict(),
                        "config": dataclasses.asdict(self.cfg),
                        "global_step": self.global_step,
                    },
                    str(best_ckpt_path),
                )
                logger.info(f"Saved best checkpoint to {best_ckpt_path}")

        total_time = time.time() - start_time
        logger.info(f"Training finished in {total_time/3600:.2f}h. Best valid BLEU={best_valid_bleu:.2f}")

        # æµ‹è¯•é›†è¯„ä¼°ï¼ˆä½¿ç”¨æœ€ä½³æ¨¡å‹ï¼‰
        test_bleu = 0.0
        if best_ckpt_path and os.path.exists(best_ckpt_path):
            logger.info(f"Loading best checkpoint {best_ckpt_path} for test evaluation ...")
            ckpt = torch.load(best_ckpt_path, map_location=self.device)
            model.load_state_dict(ckpt["model"])
            test_bleu = self._evaluate_bleu(model, test_loader)
            logger.info(f"[Test] BLEU={test_bleu:.2f}")
            assert self.writer is not None
            self.writer.add_scalar("test/BLEU", test_bleu, self.global_step)

        # å…³é—­ writer
        if self.writer is not None:
            self.writer.close()

        return {"best_valid_bleu": best_valid_bleu, "test_bleu": test_bleu}

# -----------------------------
# Ablation Orchestrator
# -----------------------------

class AblationRunner:
    """Run a set of ablation experiments and collate results."""

    def __init__(self, base_cfg: ExperimentConfig) -> None:
        self.base_cfg = base_cfg
        self.results: List[Dict[str, Any]] = []

    def _run_single(self, cfg: ExperimentConfig) -> Dict[str, Any]:
        # è¿è¡Œå•æ¬¡å®éªŒï¼ˆåŒ…å«è®­ç»ƒä¸è¯„ä¼°ï¼‰ï¼Œå¹¶è®°å½•ç»“æœ
        set_global_seed(cfg.seed)
        logger.info(f"Running experiment: {cfg.run_name} | group={cfg.group}")
        logger.info(json.dumps(dataclasses.asdict(cfg), indent=2, ensure_ascii=False))

        data_mod = WMT14DataModule(cfg)
        data_mod.prepare()

        trainer = Trainer(cfg, data_mod)
        result = trainer.train()
        result_row = {
            "run_name": cfg.run_name,
            "group": cfg.group,
            "d_model": cfg.d_model,
            "d_ff": cfg.d_ff,
            "n_heads": cfg.n_heads,
            "dropout": cfg.dropout,
            "pos_encoding": cfg.pos_encoding,
            "best_valid_bleu": result["best_valid_bleu"],
            "test_bleu": result["test_bleu"],
        }
        self.results.append(result_row)
        # å°†ç»“æœå†™å…¥ group ç›®å½•ä¸‹ JSON
        out_dir = ensure_dir(Path(cfg.log_dir) / cfg.group)
        with open(out_dir / f"summary_{int(time.time())}.json", "w", encoding="utf-8") as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        return result_row

    def run_group(self, group: Literal["heads", "dimensions", "dropout", "posenc", "baseline"]) -> List[Dict[str, Any]]:
        """Run an ablation group similar to Table 3 in the paper.

        Args:
            group: One of "heads", "dimensions", "dropout", "posenc", "baseline".

        Returns:
            List of results dicts.
        """
        cfgs: List[ExperimentConfig] = []
        base = dataclasses.replace(self.base_cfg)

        if group == "baseline":
            cfgs = [dataclasses.replace(base, run_name=f"baseline_{base.src_lang}-{base.tgt_lang}")]
        elif group == "heads":
            # Vary number of heads keeping computation roughly similar by adjusting per-head dim
            for h in [1, 4, 8, 16]:
                # ä¿æŒ d_model ä¸å˜ï¼ˆå®é™…è®ºæ–‡é‡Œä¿æŒ per-head dim å˜åŠ¨ï¼‰
                cfgs.append(
                    dataclasses.replace(
                        base,
                        n_heads=h,
                        run_name=f"heads_h{h}_{base.src_lang}-{base.tgt_lang}",
                    )
                )
        elif group == "dimensions":
            # Vary d_model and d_ff
            for (dm, df) in [(256, 1024), (512, 2048), (1024, 4096)]:
                cfgs.append(
                    dataclasses.replace(
                        base,
                        d_model=dm,
                        d_ff=df,
                        n_heads=8 if dm % 8 == 0 else 4,  # ä¿è¯å¯æ•´é™¤
                        run_name=f"dim_dm{dm}_df{df}_{base.src_lang}-{base.tgt_lang}",
                    )
                )
        elif group == "dropout":
            for p in [0.0, 0.1, 0.2, 0.3]:
                cfgs.append(
                    dataclasses.replace(
                        base,
                        dropout=p,
                        run_name=f"dropout_p{str(p).replace('.','_')}_{base.src_lang}-{base.tgt_lang}",
                    )
                )
        elif group == "posenc":
            for t in ["sinusoidal", "learned"]:
                cfgs.append(
                    dataclasses.replace(
                        base,
                        pos_encoding=t,  # type: ignore[arg-type]
                        run_name=f"posenc_{t}_{base.src_lang}-{base.tgt_lang}",
                    )
                )
        else:
            raise ValueError(f"Unknown group: {group}")

        all_results = []
        for cfg in cfgs:
            all_results.append(self._run_single(cfg))
        return all_results

# -----------------------------
# Sanity Checks
# -----------------------------

def run_sanity_checks() -> None:
    """Run minimal sanity checks for shapes and masks.

    This does not train; it only validates forward pass shapes and decoding.
    """
    logger.info("Running sanity checks for model shapes and logic ...")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    d_model, n_heads, d_ff = 256, 4, 1024
    vocab = 100
    max_len = 64
    model = TransformerSeq2Seq(
        vocab_src=vocab,
        vocab_tgt=vocab,
        d_model=d_model,
        n_heads=n_heads,
        n_layers=2,
        d_ff=d_ff,
        dropout=0.1,
        max_len=max_len,
        pos_encoding="sinusoidal",
        weight_tying=False,
    ).to(device)

    B, S, T = 2, 10, 12
    src = torch.randint(4, vocab, (B, S), device=device)
    tgt_in = torch.randint(4, vocab, (B, T), device=device)

    src_kpm = torch.zeros((B, S), dtype=torch.bool, device=device)
    tgt_kpm = torch.zeros((B, T), dtype=torch.bool, device=device)
    tgt_mask = torch.triu(torch.ones((1, T, T), dtype=torch.bool, device=device), diagonal=1)

    logits = model(
        src_ids=src,
        tgt_in=tgt_in,
        tgt_mask=tgt_mask,
        src_key_padding_mask=src_kpm,
        tgt_key_padding_mask=tgt_kpm,
    )
    assert logits.shape == (B, T, vocab), f"Unexpected logits shape: {logits.shape}"

    gen = model.greedy_decode(
        src_ids=src,
        src_key_padding_mask=src_kpm,
        max_len=20,
        bos_id=1,
        eos_id=2,
    )
    assert gen.shape[0] == B and gen.shape[1] >= 1, "Greedy decode shape mismatch."
    logger.info("Sanity checks passed âœ…")

# -----------------------------
# Main and CLI
# -----------------------------

def parse_args(argv: Optional[Sequence[str]] = None) -> argparse.Namespace:
    """Parse CLI arguments.

    Args:
        argv: Optional argument sequence.

    Returns:
        Parsed namespace.
    """
    parser = argparse.ArgumentParser(
        description="Transformer Ablation Study on WMT14 (PyTorch + tensorboardX + loguru)"
    )
    parser.add_argument("--run_name", type=str, default="baseline_en-de", help="Run name.")
    parser.add_argument("--group", type=str, default="baseline", choices=["baseline", "heads", "dimensions", "dropout", "posenc"], help="Ablation group.")
    parser.add_argument("--src_lang", type=str, default="en", help="Source language.")
    parser.add_argument("--tgt_lang", type=str, default="de", help="Target language.")
    parser.add_argument("--vocab_size", type=int, default=37000, help="SentencePiece vocab size.")
    parser.add_argument("--max_len", type=int, default=256, help="Max token length.")
    parser.add_argument("--batch_size", type=int, default=8192, help="Approx tokens per batch (heuristic).")
    parser.add_argument("--epochs", type=int, default=10, help="Number of epochs.")
    parser.add_argument("--lr", type=float, default=2.0, help="Base LR factor (Noam).")
    parser.add_argument("--warmup", type=int, default=4000, help="Warmup steps.")
    parser.add_argument("--label_smoothing", type=float, default=0.1, help="Label smoothing epsilon.")
    parser.add_argument("--dropout", type=float, default=0.1, help="Dropout.")
    parser.add_argument("--d_model", type=int, default=512, help="Model hidden size.")
    parser.add_argument("--n_heads", type=int, default=8, help="Number of attention heads.")
    parser.add_argument("--n_layers", type=int, default=6, help="Number of layers.")
    parser.add_argument("--d_ff", type=int, default=2048, help="FFN hidden size.")
    parser.add_argument("--pos_enc", type=str, default="sinusoidal", choices=["sinusoidal", "learned"], help="Positional encoding type.")
    parser.add_argument("--no_tying", action="store_true", help="Disable weight tying.")
    parser.add_argument("--grad_clip", type=float, default=1.0, help="Grad clipping norm.")
    parser.add_argument("--no_fp16", action="store_true", help="Disable mixed precision.")
    parser.add_argument("--save_every", type=int, default=5000, help="Save checkpoint every N steps.")
    parser.add_argument("--log_every", type=int, default=100, help="Log every N steps.")
    parser.add_argument("--eval_every", type=int, default=5000, help="Eval every N steps.")
    parser.add_argument("--num_workers", type=int, default=4, help="DataLoader workers.")
    parser.add_argument("--seed", type=int, default=42, help="Random seed.")
    parser.add_argument("--device", type=str, default="cuda" if torch.cuda.is_available() else "cpu", help="Device.")
    parser.add_argument("--log_dir", type=str, default="runs", help="TensorBoard log dir.")
    parser.add_argument("--save_dir", type=str, default="checkpoints", help="Checkpoint dir.")
    parser.add_argument("--data_dir", type=str, default="data_wmt14", help="Local data dir fallback.")
    parser.add_argument("--spm_dir", type=str, default="spm_models", help="SentencePiece model dir.")
    parser.add_argument("--max_train_samples", type=int, default=None, help="Limit train samples (debug).")
    parser.add_argument("--max_eval_samples", type=int, default=None, help="Limit eval samples (debug).")
    parser.add_argument("--sanity_check", action="store_true", help="Run sanity checks and exit.")
    return parser.parse_args(argv)

def build_config_from_args(args: argparse.Namespace) -> ExperimentConfig:
    """Build ExperimentConfig from argparse args.

    Args:
        args: Parsed arguments.

    Returns:
        ExperimentConfig instance.
    """
    cfg = ExperimentConfig(
        run_name=args.run_name,
        log_dir=args.log_dir,
        save_dir=args.save_dir,
        data_dir=args.data_dir,
        spm_dir=args.spm_dir,
        src_lang=args.src_lang,
        tgt_lang=args.tgt_lang,
        vocab_size=args.vocab_size,
        max_len=args.max_len,
        batch_size=args.batch_size,
        num_epochs=args.epochs,
        lr=args.lr,
        warmup_steps=args.warmup,
        label_smoothing=args.label_smoothing,
        dropout=args.dropout,
        d_model=args.d_model,
        n_heads=args.n_heads,
        n_layers=args.n_layers,
        d_ff=args.d_ff,
        pos_encoding=args.pos_enc,
        weight_tying=not args.no_tying,
        grad_clip=args.grad_clip,
        fp16=not args.no_fp16,
        save_every=args.save_every,
        log_every=args.log_every,
        eval_every=args.eval_every,
        num_workers=args.num_workers,
        seed=args.seed,
        device=args.device,
        max_train_samples=args.max_train_samples,
        max_eval_samples=args.max_eval_samples,
        group=args.group,
    )
    return cfg

def main(argv: Optional[Sequence[str]] = None) -> None:
    """Main entry point for ablation experiments."""
    args = parse_args(argv)
    # è®¾ç½®æ—¥å¿—æ ¼å¼
    logger.remove()
    logger.add(sys.stderr, level="INFO", format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{message}</cyan>")

    if args.sanity_check:
        run_sanity_checks()
        return

    cfg = build_config_from_args(args)
    set_global_seed(cfg.seed)

    # å•ç»„/å¤šç»„æ¶ˆèå®éªŒå…¥å£
    ablation = AblationRunner(cfg)
    results = ablation.run_group(cfg.group)

    # æ‰“å°æ€»è§ˆè¡¨
    logger.info("==== Ablation Summary ====")
    for row in results:
        logger.info(
            f"[{row['run_name']}] h={row['n_heads']} d_model={row['d_model']} d_ff={row['d_ff']} "
            f"dropout={row['dropout']} pos={row['pos_encoding']} | "
            f"best_valid_BLEU={row['best_valid_bleu']:.2f} test_BLEU={row['test_bleu']:.2f}"
        )

if __name__ == "__main__":
    main()
```

* * *

âœ… å…³é”®æ­£ç¡®æ€§ä¸é€»è¾‘å¤æ ¸ï¼ˆä¸ä¾èµ–è¿è¡Œçš„æ ¸æŸ¥æ­¥éª¤ï¼‰
========================

ä¸‹é¢æ˜¯å¯¹æ ¸å¿ƒæ¨¡å—çš„**é€ç‚¹æ ¸æŸ¥**ï¼ˆä¿è¯é€»è¾‘ã€è¾¹ç•Œã€å½¢çŠ¶ä¸€è‡´æ€§ï¼‰ï¼š

1.  **è¾¹ç•Œä¸çº¦æŸæ£€æŸ¥**
    *   `d_model % n_heads == 0`ï¼šåœ¨ `TransformerSeq2Seq.__init__` æ˜¾å¼æ ¡éªŒï¼Œé¿å…å¤´ç»´åº¦éæ•´æ•°ã€‚
    *   `0 â‰¤ dropout < 1`ã€`0 â‰¤ label_smoothing < 1`ï¼šæ„é€ æ—¶æ ¡éªŒï¼Œé˜²æ­¢éæ³•è¶…å‚ã€‚
    *   æƒé‡å…±äº«ï¼ˆtgt embedding â†” generatorï¼‰æ—¶ï¼Œå…ˆæ ¡éªŒä¸¤è€…æƒé‡å°ºå¯¸ä¸€è‡´ã€‚
2.  **æ©ç é€»è¾‘æ£€æŸ¥**
    *   `DynamicBatchCollator`ï¼š
        *   `src_key_padding_mask` / `tgt_key_padding_mask` è¯­ä¹‰ä¸ `nn.Transformer` ä¸€è‡´ï¼ˆ`True` è¡¨ç¤º PADï¼‰ã€‚
        *   `tgt_mask` ä½¿ç”¨ä¸Šä¸‰è§’ `True` å®ç°å› æœå±è”½ï¼Œå¹¶ä¼ å…¥ `decoder`ã€‚
        *   `tgt_in`/`tgt_out` é€šè¿‡ä½ç§»å®ç°è‡ªå›å½’è®­ç»ƒï¼ˆä¸è®ºæ–‡ä¸€è‡´ï¼‰ã€‚
    *   `greedy_decode` ä¸­é€æ­¥æ„é€  `subsequent_mask` å¹¶åœ¨ `decoder` ä½¿ç”¨ï¼›`memory_key_padding_mask` å§‹ç»ˆæ˜¯æºç«¯ pad maskã€‚
3.  **å½¢çŠ¶ä¸ç»´åº¦æ£€æŸ¥**
    *   `batch_first=True`ï¼Œå…¨ç¨‹ä½¿ç”¨ (B, T, D)ï¼›`tgt_mask` ä¼ å…¥ `decoder` æ—¶åšäº† `[..., 0]` è½¬æ¢ä¸º (T, T)ã€‚
    *   `LabelSmoothingLoss` å±•å¹³ä¸º (B_T, V) ä¸ (B_T,) åè®¡ç®— KLDivï¼Œmask æ‰ PADã€‚
4.  **å­¦ä¹ ç‡è°ƒåº¦**
    *   `NoamScheduler.get_lr()` ä½¿ç”¨ `(d_model^-0.5) * min(step^-0.5, step*warmup^-1.5)`ï¼Œç¬¦åˆè®ºæ–‡å…¬å¼ï¼ˆ3ï¼‰ã€‚
5.  **ä½ç½®ç¼–ç **
    *   æä¾› `SinusoidalPositionalEncoding` ä¸ `LearnedPositionalEncoding`ï¼›ä¸¤è€…å‡ä¸è¾“å…¥å½¢çŠ¶åŒ¹é… (B, T, D)ã€‚
6.  **æƒé‡å…±äº«**
    *   ä¸è®ºæ–‡ä¸€è‡´ï¼š`generator.weight = tgt_embed.weight`ï¼Œç¡®ä¿ logits æŠ•å½±å…±äº«ã€‚
7.  **è¯„ä¼°ä¸æŒ‡æ ‡**
    *   `sacrebleu.corpus_bleu` ä»¥ `(hyps, [refs])` æ–¹å¼è®¡ç®—ã€‚è´ªå¿ƒè§£ç æˆªæ–­åˆ° EOSï¼Œä¸”å»é™¤ BOS/PADã€‚
8.  **é²æ£’æ€§**
    *   æ•°æ®åŠ è½½ï¼šä¼˜å…ˆ HuggingFace `wmt14`ï¼Œå¤±è´¥å›é€€æœ¬åœ° TSV æ–‡ä»¶ï¼ˆ`data_dir/train.en-de.tsv` ç­‰ï¼‰ã€‚
    *   SentencePieceï¼šè‹¥æ¨¡å‹ä¸å­˜åœ¨åˆ™è®­ç»ƒï¼Œå¦åˆ™åŠ è½½ï¼›æ¸…ç†ä¸´æ—¶æ–‡ä»¶ã€‚
    *   è®­ç»ƒè¿‡ç¨‹ï¼šæ··åˆç²¾åº¦ + æ¢¯åº¦è£å‰ª + æŒ‰æ­¥ä¿å­˜/è¯„ä¼° + æœ€ä¼˜æ¨¡å‹å¦å­˜ã€‚
9.  **Sanity Checkï¼ˆå¯è¿è¡Œè‡ªæ£€ï¼‰**
    *   `--sanity_check` å°†æ‰§è¡Œä¸€ä¸ªå°å‹å‰å‘/è§£ç æ£€æŸ¥ï¼šç¡®ä¿ logits å½¢çŠ¶ä¸º (B, T, V)ï¼Œgreedy decode è¾“å‡º (B, T\_gen)ã€‚
10.  **æ¶ˆèç»„è£…**
    *   `AblationRunner.run_group()` æ”¯æŒ `baseline/heads/dimensions/dropout/posenc` äº”ç»„ï¼Œä¸è®ºæ–‡ Table 3 è¦ç‚¹å¯¹é½ï¼ˆå¯è¿›ä¸€æ­¥æ‰©å±• beamsã€å±‚æ•°ç­‰ï¼‰ã€‚

> ä»¥ä¸Šæ ¸æŸ¥è¦†ç›–äº†**æ©ç è¯­ä¹‰**ã€**å½¢çŠ¶ä¸€è‡´æ€§**ã€**å­¦ä¹ ç‡ç­–ç•¥**ã€**ä½ç½®ç¼–ç **ã€**æƒé‡å…±äº«**ã€**æ•°æ®/è¯„ä¼°**ç­‰å…³é”®æ˜“é”™ç‚¹ï¼Œç¬¦åˆè®ºæ–‡ä¸å·¥ä¸šå®è·µè¦æ±‚ã€‚

* * *

ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‘½ä»¤è¡Œï¼‰
---------

*   **åŸºçº¿ï¼ˆè‹±â†’å¾·ï¼‰**
    ```bash
    python main.py --group baseline --src_lang en --tgt_lang de --run_name baseline_en-de
    ```
*   **å¤šå¤´æ•°æ¶ˆè**
    ```bash
    python main.py --group heads --src_lang en --tgt_lang de --epochs 10
    ```
*   **æ¨¡å‹ç»´åº¦æ¶ˆè**
    ```bash
    python main.py --group dimensions --src_lang en --tgt_lang de --epochs 10
    ```
*   **Dropout æ¶ˆè**
    ```bash
    python main.py --group dropout --src_lang en --tgt_lang de --epochs 10
    ```
*   **ä½ç½®ç¼–ç æ¶ˆè**
    ```bash
    python main.py --group posenc --src_lang en --tgt_lang de --epochs 10
    ```
*   **å¿«é€Ÿè‡ªæ£€ï¼ˆä¸è®­ç»ƒï¼‰**
    ```bash
    python main.py --sanity_check
    ```

> é‡è¦æç¤ºï¼šé¦–æ¬¡è¿è¡Œå»ºè®®æŒ‡å®š `--max_train_samples/--max_eval_samples` åšå°é›†è°ƒé€šï¼›æ­£å¼è®­ç»ƒè¯·ç¡®ä¿ç£ç›˜/æ˜¾å­˜èµ„æºå……è¶³ï¼Œå¹¶æ ¹æ®æœºå™¨é…ç½®åˆé€‚åœ°è°ƒå° `batch_size` æˆ– `max_len`ã€‚TensorBoard å¯åŠ¨ï¼š`tensorboard --logdir runs`ã€‚

å¦‚æœä½ å¸Œæœ›æˆ‘æŠŠ **beam search**ã€**æ¢¯åº¦ç´¯ç§¯**ã€**å¤šå¡åˆ†å¸ƒå¼ï¼ˆDDPï¼‰**ã€**çº¿æ€§æ³¨æ„åŠ›æ›¿æ¢ä»¥æ”¯æŒé•¿åºåˆ—** ç­‰ä¹Ÿä¸€èµ·åŠ ä¸Šï¼Œæˆ‘å¯ä»¥ç»§ç»­æ‰©å±•è¿™ä¸ªå·¥ç¨‹ç‰ˆè„šæ‰‹æ¶ã€‚



---
Powered by [ChatGPT Exporter](https://www.chatgptexporter.com)